{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYoGJYQCOWyC"
   },
   "source": [
    "# First Neural Network with Keras\n",
    "In this tutorial, you will build your first **multilayer perceptron (MLP)** model (also your first neural network) in Python with Keras. As you will see, Keras is a easy-to-use deep API that allows you to easily build, train, evaluate and execute deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvJEQJmZOWyF"
   },
   "source": [
    "## 1. Load the dataset\n",
    "In this tutorial, we are going to use Pima Indians Diabetes dataset which is a standard machine learning dataset from the UCI Machine Learning repository. The dataset can be downloaded from <a href=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\" target=\"_blank\">here</a>. Place it in the same location as this notebook file.\n",
    "\n",
    "This is a comparably small dataset, with 768 samples in total. There are eight input features (X) and one output variable (y).\n",
    "\n",
    "Input features (X):\n",
    "\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "\n",
    "Output Variables (y):\n",
    "\n",
    "1. Class label (1 for diabetes, 0 for not)\n",
    "\n",
    "First we need import all necessary libraries which we will need to work upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A9nFOtMSOWyG"
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from numpy import loadtxt #loadtxt function to load data from a text file\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I__5DLxEOWyH"
   },
   "source": [
    "Here we use `numpy` function `loadtxt` to load the CSV file. In the file, each row corresponds to one example, with nine columns. We can then split them into the input features (X) and output labels (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1760357865436,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "PMccf-Zkf-wL",
    "outputId": "7a74e98d-c50d-4f8f-d794-1dfb0838f28c"
   },
   "outputs": [],
   "source": [
    "# if using Google Colab\n",
    "#from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eUCj69WcOWyI"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv',delimiter=',')\n",
    "# if not using Google colab\n",
    "dataset = loadtxt('pima-indians-diabetes.csv',delimiter=',')\n",
    "# split into input X and output y variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqdXb0RvOWyI"
   },
   "source": [
    "Let's print the dimension of X. You may also want to have a look of a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1760357865449,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "yFTJ6O1mOWyJ",
    "outputId": "93265cc4-c15d-4bdc-d692-fe19c2d07dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "[  6.    148.     72.     35.      0.     33.6     0.627  50.      1.   ]\n",
      "[ 1.    85.    66.    29.     0.    26.6    0.351 31.     0.   ]\n",
      "[  8.    183.     64.      0.      0.     23.3     0.672  32.      1.   ]\n",
      "[ 1.    89.    66.    23.    94.    28.1    0.167 21.     0.   ]\n",
      "[  0.    137.     40.     35.    168.     43.1     2.288  33.      1.   ]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "for i in range(5): # print the first 5 rows of the dataset\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOi0slwVOWyK"
   },
   "source": [
    "Let's split them into training set and test set by using the `train_test_split( )` method from `sklearn`. `test_size = 0.2` means 20% examples are used for test.\n",
    "\n",
    "You must **treat the test set as unseen data**, which means any model adjustment must be done only on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YKPrP_Z-OWyK"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feRMm1CeOWyL"
   },
   "source": [
    "## 2. Prepare the data\n",
    "Usually there is a pre-processing step before building the model. What pre-processing should be carried out depends on the data and any requirement for the model. For this dataset, the eight features are in variant ranges and scales, which may lead to unstable weight learning. In this case, the common practice is to standardize the input data, to make each feature to be mean 0 and unit variance. The network would then be trained on a more stable distribution of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JaXPTN_0OWyL"
   },
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "mean_train = X_train.mean(axis=0) # compute the mean of each feature in the training set. axis=0 means we are computing the mean along the columns (features).\n",
    "std_train = X_train.std(axis=0) # compute the standard deviation of each feature in the training set.\n",
    "X_train = (X_train - mean_train) / std_train \n",
    "X_test = (X_test - mean_train) / std_train # normalize the test set using the mean and std of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFQTcq27OWyM"
   },
   "source": [
    "## 3. Build your network\n",
    "Now we are ready to build our neural network. In Keras, we first create a `sequential` model, then add layers one by one.\n",
    "\n",
    "As there are only 8 input features in this dataset, we may consider to build a small-size MLP: three fully connected layers (or `Dense` layers). For each `Dense` layer, we specify the number of neurons in the layer as the first argument, and specify the activation function using the `activation` argument. For the first `Dense` layer, we also need give the input feature dimension (`input_dim=8`).\n",
    "\n",
    "We use the Rectified Linear Unit (ReLU) activation function for the 2 hidden layers, as ReLU usually produces better performance compared to the Sigmoid or Tanh functions. We use a sigmoid on the output layer to ensure the network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5.\n",
    "\n",
    "Now lets's interprete the following code as follows.\n",
    "\n",
    "1. The model expects the input data containing 8 features (or columns).\n",
    "2. We add the first hidden layer with 12 neurons and use the ReLU activation fuction.\n",
    "3. We add the second hidden layer with 6 neurons and use the ReLu activation function.\n",
    "4. Finally, we add the output layer with 1 neuron and use the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1760357865625,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "bFVpAK52OWyM",
    "outputId": "ca1d6dd7-92bc-469d-bf4f-afafb69202fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# define a keras model of a MLP network with three Dense layers\n",
    "model = Sequential() # needs to be a sequential model as we are going to add layers one after the other\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu')) # first hidden layer with 12 neurons, input dimension is 8 (number of features), activation function is relu\n",
    "model.add(Dense(6, activation = 'relu')) # second hidden layer with 6 neurons, activation function is relu\n",
    "model.add(Dense(1, activation = 'sigmoid')) # output layer with 1 neuron, activation function is sigmoid for binary classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEVNLGv4OWyM"
   },
   "source": [
    "You can use the `summary()` method to display all the model's layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1760357865697,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "8UqqdRE7OWyN",
    "outputId": "50efa127-128e-4823-c532-5f6329d9b0f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m108\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m78\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUwvl2kpOWyN"
   },
   "source": [
    "Dense layers often have a lot of parameters. Even we build such a small MLP, there are 193 parameters in total. Let's see how the numbers are calculated. For example, the first hidden layer has 8 x 12 connection weights, plus 8 bias terms, which adds up to 108 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAgkp6c-OWyN"
   },
   "source": [
    "## 3. Compile the model\n",
    "After the model is created, you must call the `compile()` method to specify the `loss` function and the `optimizer` to use. Optionally, you can specify a list of extra `metrics` to compute and report during training and evaluation.\n",
    "\n",
    "Regarding the binary classification problem, the typical loss function is `binary_crossentropy` defined in Keras.\n",
    "\n",
    "We choose the efficient stochastic gradient descent algorithm `adam` as the optimizer. It is a popular choice as it adaptively chooses the learning rate and gives good results in a wide range of problems.\n",
    "\n",
    "Since it is a classification problem, it is more intuitive to measure and report the classification `accuracy`, defined via the `metrics` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gaf83AhGOWyN"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haJ5xelROWyO"
   },
   "source": [
    "## 4. Train and validate the model\n",
    "Now the model is ready to be trained. For this we simply call its `fit()` method. We'll train the model for 120 epochs (120 itrations over all samples in the training set), in mini-batches of 32 samples. (If you don't know what mini-batch means, don't worry, we will talk about it in our later lectures.)\n",
    "\n",
    "We also split 25% examples in the training set as a validation set (this is optional). Keras will measure the loss and the accuracy on this validation set at the end of each epoch, which is very useful to see how well the model performs. Based on the performance on the validation set, we could modify the model and tune the hyperparameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32220,
     "status": "ok",
     "timestamp": 1760357898006,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "epGxfRUSOWyO",
    "outputId": "4d82ed39-876e-4629-8640-7ec364fcb1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4623 - loss: 0.7125 - val_accuracy: 0.5285 - val_loss: 0.7147\n",
      "Epoch 2/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 0.6925 - val_accuracy: 0.5772 - val_loss: 0.7009\n",
      "Epoch 3/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6477 - loss: 0.6787 - val_accuracy: 0.5935 - val_loss: 0.6903\n",
      "Epoch 4/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6721 - loss: 0.6638 - val_accuracy: 0.6341 - val_loss: 0.6760\n",
      "Epoch 5/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.6448 - val_accuracy: 0.6585 - val_loss: 0.6567\n",
      "Epoch 6/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.6189 - val_accuracy: 0.6829 - val_loss: 0.6344\n",
      "Epoch 7/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.5876 - val_accuracy: 0.6829 - val_loss: 0.6074\n",
      "Epoch 8/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5552 - val_accuracy: 0.6829 - val_loss: 0.5764\n",
      "Epoch 9/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.5269 - val_accuracy: 0.6992 - val_loss: 0.5525\n",
      "Epoch 10/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.5076 - val_accuracy: 0.7154 - val_loss: 0.5396\n",
      "Epoch 11/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.4902 - val_accuracy: 0.7480 - val_loss: 0.5205\n",
      "Epoch 12/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4766 - val_accuracy: 0.7642 - val_loss: 0.5060\n",
      "Epoch 13/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.4665 - val_accuracy: 0.7642 - val_loss: 0.4975\n",
      "Epoch 14/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4573 - val_accuracy: 0.7724 - val_loss: 0.4931\n",
      "Epoch 15/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4503 - val_accuracy: 0.7642 - val_loss: 0.4854\n",
      "Epoch 16/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.4445 - val_accuracy: 0.7561 - val_loss: 0.4859\n",
      "Epoch 17/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4417 - val_accuracy: 0.7561 - val_loss: 0.4861\n",
      "Epoch 18/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4369 - val_accuracy: 0.7561 - val_loss: 0.4830\n",
      "Epoch 19/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.4333 - val_accuracy: 0.7642 - val_loss: 0.4826\n",
      "Epoch 20/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4296 - val_accuracy: 0.7724 - val_loss: 0.4809\n",
      "Epoch 21/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4267 - val_accuracy: 0.7642 - val_loss: 0.4816\n",
      "Epoch 22/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4238 - val_accuracy: 0.7724 - val_loss: 0.4826\n",
      "Epoch 23/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4213 - val_accuracy: 0.7724 - val_loss: 0.4824\n",
      "Epoch 24/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4197 - val_accuracy: 0.7724 - val_loss: 0.4804\n",
      "Epoch 25/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4164 - val_accuracy: 0.7724 - val_loss: 0.4845\n",
      "Epoch 26/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.4152 - val_accuracy: 0.7724 - val_loss: 0.4877\n",
      "Epoch 27/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.4135 - val_accuracy: 0.7724 - val_loss: 0.4839\n",
      "Epoch 28/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4120 - val_accuracy: 0.7724 - val_loss: 0.4903\n",
      "Epoch 29/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4098 - val_accuracy: 0.7724 - val_loss: 0.4900\n",
      "Epoch 30/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4077 - val_accuracy: 0.7642 - val_loss: 0.4873\n",
      "Epoch 31/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4080 - val_accuracy: 0.7642 - val_loss: 0.4905\n",
      "Epoch 32/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4047 - val_accuracy: 0.7642 - val_loss: 0.4875\n",
      "Epoch 33/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4040 - val_accuracy: 0.7561 - val_loss: 0.4868\n",
      "Epoch 34/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4022 - val_accuracy: 0.7561 - val_loss: 0.4896\n",
      "Epoch 35/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4004 - val_accuracy: 0.7561 - val_loss: 0.4900\n",
      "Epoch 36/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3990 - val_accuracy: 0.7642 - val_loss: 0.4895\n",
      "Epoch 37/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3979 - val_accuracy: 0.7561 - val_loss: 0.4914\n",
      "Epoch 38/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3976 - val_accuracy: 0.7561 - val_loss: 0.4942\n",
      "Epoch 39/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3957 - val_accuracy: 0.7642 - val_loss: 0.4917\n",
      "Epoch 40/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3945 - val_accuracy: 0.7642 - val_loss: 0.4929\n",
      "Epoch 41/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3934 - val_accuracy: 0.7642 - val_loss: 0.4951\n",
      "Epoch 42/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3925 - val_accuracy: 0.7642 - val_loss: 0.4949\n",
      "Epoch 43/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3910 - val_accuracy: 0.7642 - val_loss: 0.4950\n",
      "Epoch 44/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3900 - val_accuracy: 0.7642 - val_loss: 0.4957\n",
      "Epoch 45/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3896 - val_accuracy: 0.7642 - val_loss: 0.4958\n",
      "Epoch 46/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3900 - val_accuracy: 0.7642 - val_loss: 0.4941\n",
      "Epoch 47/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3887 - val_accuracy: 0.7642 - val_loss: 0.4961\n",
      "Epoch 48/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3873 - val_accuracy: 0.7642 - val_loss: 0.4963\n",
      "Epoch 49/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3866 - val_accuracy: 0.7642 - val_loss: 0.4977\n",
      "Epoch 50/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3854 - val_accuracy: 0.7642 - val_loss: 0.4950\n",
      "Epoch 51/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3844 - val_accuracy: 0.7642 - val_loss: 0.4971\n",
      "Epoch 52/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3841 - val_accuracy: 0.7642 - val_loss: 0.4991\n",
      "Epoch 53/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.3829 - val_accuracy: 0.7642 - val_loss: 0.4995\n",
      "Epoch 54/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3843 - val_accuracy: 0.7642 - val_loss: 0.5011\n",
      "Epoch 55/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3837 - val_accuracy: 0.7642 - val_loss: 0.5016\n",
      "Epoch 56/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3824 - val_accuracy: 0.7724 - val_loss: 0.4996\n",
      "Epoch 57/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3812 - val_accuracy: 0.7724 - val_loss: 0.5007\n",
      "Epoch 58/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3801 - val_accuracy: 0.7724 - val_loss: 0.5014\n",
      "Epoch 59/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3795 - val_accuracy: 0.7724 - val_loss: 0.5008\n",
      "Epoch 60/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3803 - val_accuracy: 0.7805 - val_loss: 0.5020\n",
      "Epoch 61/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3775 - val_accuracy: 0.7805 - val_loss: 0.5031\n",
      "Epoch 62/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3782 - val_accuracy: 0.7805 - val_loss: 0.5008\n",
      "Epoch 63/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3775 - val_accuracy: 0.7805 - val_loss: 0.5032\n",
      "Epoch 64/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3770 - val_accuracy: 0.7805 - val_loss: 0.5043\n",
      "Epoch 65/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3757 - val_accuracy: 0.7805 - val_loss: 0.5043\n",
      "Epoch 66/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3748 - val_accuracy: 0.7805 - val_loss: 0.5052\n",
      "Epoch 67/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3751 - val_accuracy: 0.7805 - val_loss: 0.5062\n",
      "Epoch 68/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3746 - val_accuracy: 0.7805 - val_loss: 0.5065\n",
      "Epoch 69/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3749 - val_accuracy: 0.7642 - val_loss: 0.5093\n",
      "Epoch 70/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3726 - val_accuracy: 0.7642 - val_loss: 0.5095\n",
      "Epoch 71/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3718 - val_accuracy: 0.7724 - val_loss: 0.5095\n",
      "Epoch 72/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3726 - val_accuracy: 0.7805 - val_loss: 0.5123\n",
      "Epoch 73/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3715 - val_accuracy: 0.7642 - val_loss: 0.5148\n",
      "Epoch 74/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3715 - val_accuracy: 0.7805 - val_loss: 0.5112\n",
      "Epoch 75/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.3710 - val_accuracy: 0.7805 - val_loss: 0.5091\n",
      "Epoch 76/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3704 - val_accuracy: 0.7805 - val_loss: 0.5108\n",
      "Epoch 77/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3699 - val_accuracy: 0.7805 - val_loss: 0.5091\n",
      "Epoch 78/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3704 - val_accuracy: 0.7805 - val_loss: 0.5108\n",
      "Epoch 79/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3698 - val_accuracy: 0.7805 - val_loss: 0.5118\n",
      "Epoch 80/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3674 - val_accuracy: 0.7724 - val_loss: 0.5101\n",
      "Epoch 81/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3666 - val_accuracy: 0.7886 - val_loss: 0.5117\n",
      "Epoch 82/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3661 - val_accuracy: 0.7805 - val_loss: 0.5122\n",
      "Epoch 83/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3666 - val_accuracy: 0.7805 - val_loss: 0.5160\n",
      "Epoch 84/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3659 - val_accuracy: 0.7886 - val_loss: 0.5150\n",
      "Epoch 85/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3665 - val_accuracy: 0.7886 - val_loss: 0.5160\n",
      "Epoch 86/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3653 - val_accuracy: 0.7886 - val_loss: 0.5161\n",
      "Epoch 87/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.3652 - val_accuracy: 0.7805 - val_loss: 0.5167\n",
      "Epoch 88/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3645 - val_accuracy: 0.7886 - val_loss: 0.5171\n",
      "Epoch 89/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3648 - val_accuracy: 0.7886 - val_loss: 0.5155\n",
      "Epoch 90/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3626 - val_accuracy: 0.7805 - val_loss: 0.5170\n",
      "Epoch 91/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3620 - val_accuracy: 0.7886 - val_loss: 0.5173\n",
      "Epoch 92/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3623 - val_accuracy: 0.7886 - val_loss: 0.5170\n",
      "Epoch 93/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3607 - val_accuracy: 0.7886 - val_loss: 0.5169\n",
      "Epoch 94/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3606 - val_accuracy: 0.7886 - val_loss: 0.5183\n",
      "Epoch 95/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3604 - val_accuracy: 0.7886 - val_loss: 0.5186\n",
      "Epoch 96/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3596 - val_accuracy: 0.7805 - val_loss: 0.5177\n",
      "Epoch 97/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3582 - val_accuracy: 0.7805 - val_loss: 0.5206\n",
      "Epoch 98/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3586 - val_accuracy: 0.7805 - val_loss: 0.5191\n",
      "Epoch 99/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3579 - val_accuracy: 0.7805 - val_loss: 0.5204\n",
      "Epoch 100/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3572 - val_accuracy: 0.7805 - val_loss: 0.5205\n",
      "Epoch 101/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3576 - val_accuracy: 0.7886 - val_loss: 0.5202\n",
      "Epoch 102/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3569 - val_accuracy: 0.7805 - val_loss: 0.5191\n",
      "Epoch 103/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3558 - val_accuracy: 0.7805 - val_loss: 0.5233\n",
      "Epoch 104/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3561 - val_accuracy: 0.7805 - val_loss: 0.5237\n",
      "Epoch 105/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3546 - val_accuracy: 0.7805 - val_loss: 0.5223\n",
      "Epoch 106/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3538 - val_accuracy: 0.7805 - val_loss: 0.5232\n",
      "Epoch 107/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3546 - val_accuracy: 0.7642 - val_loss: 0.5257\n",
      "Epoch 108/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3532 - val_accuracy: 0.7724 - val_loss: 0.5269\n",
      "Epoch 109/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3532 - val_accuracy: 0.7724 - val_loss: 0.5238\n",
      "Epoch 110/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3542 - val_accuracy: 0.7642 - val_loss: 0.5255\n",
      "Epoch 111/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3529 - val_accuracy: 0.7724 - val_loss: 0.5278\n",
      "Epoch 112/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3545 - val_accuracy: 0.7642 - val_loss: 0.5288\n",
      "Epoch 113/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3521 - val_accuracy: 0.7642 - val_loss: 0.5275\n",
      "Epoch 114/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3514 - val_accuracy: 0.7561 - val_loss: 0.5298\n",
      "Epoch 115/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3509 - val_accuracy: 0.7561 - val_loss: 0.5305\n",
      "Epoch 116/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3498 - val_accuracy: 0.7642 - val_loss: 0.5328\n",
      "Epoch 117/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3503 - val_accuracy: 0.7642 - val_loss: 0.5378\n",
      "Epoch 118/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3492 - val_accuracy: 0.7642 - val_loss: 0.5317\n",
      "Epoch 119/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3495 - val_accuracy: 0.7642 - val_loss: 0.5338\n",
      "Epoch 120/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3493 - val_accuracy: 0.7642 - val_loss: 0.5328\n",
      "Epoch 121/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3491 - val_accuracy: 0.7642 - val_loss: 0.5308\n",
      "Epoch 122/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3484 - val_accuracy: 0.7642 - val_loss: 0.5323\n",
      "Epoch 123/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3472 - val_accuracy: 0.7642 - val_loss: 0.5325\n",
      "Epoch 124/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3487 - val_accuracy: 0.7642 - val_loss: 0.5348\n",
      "Epoch 125/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3472 - val_accuracy: 0.7724 - val_loss: 0.5345\n",
      "Epoch 126/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3460 - val_accuracy: 0.7724 - val_loss: 0.5318\n",
      "Epoch 127/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3467 - val_accuracy: 0.7724 - val_loss: 0.5355\n",
      "Epoch 128/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3453 - val_accuracy: 0.7642 - val_loss: 0.5342\n",
      "Epoch 129/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3472 - val_accuracy: 0.7805 - val_loss: 0.5320\n",
      "Epoch 130/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3489 - val_accuracy: 0.7724 - val_loss: 0.5335\n",
      "Epoch 131/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3476 - val_accuracy: 0.7561 - val_loss: 0.5356\n",
      "Epoch 132/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3466 - val_accuracy: 0.7642 - val_loss: 0.5349\n",
      "Epoch 133/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3462 - val_accuracy: 0.7642 - val_loss: 0.5348\n",
      "Epoch 134/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.3451 - val_accuracy: 0.7724 - val_loss: 0.5392\n",
      "Epoch 135/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3441 - val_accuracy: 0.7642 - val_loss: 0.5393\n",
      "Epoch 136/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3439 - val_accuracy: 0.7642 - val_loss: 0.5399\n",
      "Epoch 137/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3434 - val_accuracy: 0.7724 - val_loss: 0.5378\n",
      "Epoch 138/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3433 - val_accuracy: 0.7642 - val_loss: 0.5385\n",
      "Epoch 139/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3432 - val_accuracy: 0.7642 - val_loss: 0.5381\n",
      "Epoch 140/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3423 - val_accuracy: 0.7642 - val_loss: 0.5397\n",
      "Epoch 141/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3418 - val_accuracy: 0.7642 - val_loss: 0.5401\n",
      "Epoch 142/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3455 - val_accuracy: 0.7561 - val_loss: 0.5370\n",
      "Epoch 143/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3427 - val_accuracy: 0.7561 - val_loss: 0.5372\n",
      "Epoch 144/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3418 - val_accuracy: 0.7642 - val_loss: 0.5390\n",
      "Epoch 145/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3411 - val_accuracy: 0.7642 - val_loss: 0.5385\n",
      "Epoch 146/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3410 - val_accuracy: 0.7561 - val_loss: 0.5388\n",
      "Epoch 147/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3401 - val_accuracy: 0.7561 - val_loss: 0.5406\n",
      "Epoch 148/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3418 - val_accuracy: 0.7642 - val_loss: 0.5415\n",
      "Epoch 149/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3401 - val_accuracy: 0.7642 - val_loss: 0.5404\n",
      "Epoch 150/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3404 - val_accuracy: 0.7642 - val_loss: 0.5416\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDUWHO92OWyO"
   },
   "source": [
    "Note that the call to` model.fit()` returns a `history` object. This `history` object contains a member `history`, which is a dictionary containing the loss and extra metrics it monitored during the training process. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1760357898025,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "FvGMOtVjOWyP",
    "outputId": "e2127aef-c9e0-4ca2-a354-16b10a7447b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMoFrH2UOWyP"
   },
   "source": [
    "If you use this dictionary to create a `panda` `DataFrame` and call its `plot()` method, you will get the four learning curves plotted in one figure. We will plot them in two separate figures, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1760357898559,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "zl3VDP9UOWyP",
    "outputId": "f4222dcd-13cd-487a-8ec0-7927e57054d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAG2CAYAAACtaYbcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcLJJREFUeJzt3Xd8FHX+x/HX7qb3RhoECL2jJKCggKiAINgFy4mIeMdhOcVylt/ZTz3P3tDzKGfvBQWlSBekN+k9lEBIIL1tsvP7Y8hCTAJJCMwmvJ+PRx7Jfndm5zOTne9+9vv9zndshmEYiIiIiFjEbnUAIiIicnZTMiIiIiKWUjIiIiIillIyIiIiIpZSMiIiIiKWUjIiIiIillIyIiIiIpZSMiIiIiKWUjIiIiIillIyIiIiIpaqcTIyf/58hg4dSnx8PDabje++++6k68ybN4+kpCT8/Pxo0aIF7777bm1iFZF6SvWGiJxIjZORvLw8unbtyltvvVWt5Xfu3MngwYPp3bs3q1at4tFHH+Wee+7h66+/rnGwIlI/qd4QkROxncqN8mw2G99++y1XXXVVlcv8/e9/Z8qUKWzcuNFdNmbMGNasWcPixYtru2kRqadUb4jIH3md7g0sXryYAQMGlCsbOHAgEyZMwOl04u3tXWGdoqIiioqK3I9dLheHDx8mMjISm812ukMWkT8wDIOcnBzi4+Ox20//UDPVGyINQ3XrjtOejBw4cICYmJhyZTExMZSUlJCenk5cXFyFdZ5//nmeeuqp0x2aiNTQnj17aNKkyWnfjuoNkYblZHXHaU9GgArfSsp6hqr6tvLII48wbtw49+OsrCyaNm3Kli1biIiIOH2BngZOp5M5c+bQr1+/Sr/NeTLFbg1PjD0nJ4fExESCg4PP2DZVb3jWe6C6FLs1PDX26tYdpz0ZiY2N5cCBA+XK0tLS8PLyIjIystJ1fH198fX1rVAeERFR5Tqeyul0EhAQQGRkpEe9QapDsVvDE2Mvi+NMdXeo3vC890B1KXZreGrs1a07Tnvnb8+ePZk5c2a5shkzZpCcnOxRB0xEPIfqDZGzS42TkdzcXFavXs3q1asB8xK81atXk5KSAphNpSNGjHAvP2bMGHbv3s24cePYuHEjEydOZMKECTzwwAN1swci4vFUb4jIidS4m2b58uX069fP/bisj/bWW29l8uTJpKamuisYgMTERKZNm8Z9993H22+/TXx8PG+88QbXXnttHYQvIvWB6g0ROZEaJyMXXXQRJ5qaZPLkyRXK+vbty8qVK2u6KamnSktLcTqdlsbgdDrx8vKisLCQ0tJSS2OpKati9/HxOW2X7are8Dyn6zzVuWcNq2L39vbG4XCc8uuckatp5OxgGAYHDhwgMzPT6lAwDIPY2Fj27NlT7+aYsCp2u91OYmIiPj4+Z2ybcuad7vNU5541rIw9LCyM2NjYU9qukhGpM2UVXHR0NAEBAZaezC6Xi9zcXIKCgs7IJF11yYrYXS4X+/fvJzU1laZNm9a7iliq73Sfpzr3rGFF7IZhkJ+fT1paGkCl8/9Ul5IRqROlpaXuCs4TLqN0uVwUFxfj5+dXLysVK2Jv1KgR+/fvp6SkRFesNFBn4jzVuWcNq2L39/cHzEvvo6Oja91lU7+Otnissr7ngIAAiyOR2irrnqlvfeVSfTpP5XQoez+dyhgkJSNSp9S8X3/pf3f20P9a6lJdvJ+UjIiIiIillIyI1KHmzZvz2muvndJrtGjRgvHjx9dNQCJSqbo4V6XuaACrnNUuuugizjnnnDqrlJYtW0ZgYGCdvJaIHKNztWFTMiJyEoZhUFpaipfXyU+XRo0anYGIRKQyZ/u5ahgGJSUl9XKuIHXTyFlr5MiRzJs3j9dffx2bzYbNZmPXrl3MnTsXm83G9OnTSU5OxtfXlwULFrB9+3auvPJKYmJiCAoKonv37syaNavca/6x6ddms/Hf//6Xq6++moCAAFq3bs2UKVNqFGdKSgpXXnklQUFBhISEMGzYMA4ePOh+fs2aNfTr14/g4GBCQkJISkpi+fLlAOzevZuhQ4cSHh5OYGAgHTt2ZNq0abU/aCIWOJPn6p/+9CeCgoKqda5+9NFHJCcnExwcTGxsLDfddJN7zo0y69ev5/LLLyckJITg4GB69+7N9u3b3c9PnDiRjh074uvrS1xcHHfddRcAu3btwmazue/nBJCZmYnNZmPu3LkA5fa/R48exMTEVHv/i4qKeOihh0hISMDX15fWrVszYcIEDMOgVatWvPTSS+WW//3337Hb7eVir0tKRuS0MAyD/OISS35ONO348V5//XV69uzJHXfcQWpqKqmpqSQkJLiff+ihh3j++efZuHEjXbp0ITc3l8GDBzNr1ixWrVrFwIEDGTp0aLl7qlTmqaeeYtiwYaxdu5bBgwdz8803c/jw4Wofx6uuuorDhw8zb948Zs6cyfbt2xk+fLh7mZtvvpkmTZqwbNkyVqxYwcMPP+yeJ+TOO++kqKiI+fPns27dOv71r38RFBRUrW3L2eF0nKsFxaV1dp7CmTtXn3nmGa666ipWr15drXO1uLiYZ555hjVr1vDdd9+xc+dORo4c6X5+37599OnTBz8/P2bPns2KFSsYNWoUJSUlAIwfP54777yTP//5z6xbt44pU6bQqlWrah+X4/f/n//8J0uWLKn2/o8YMYLPPvuMN954g40bN/Luu+8SFBSEzWZj1KhRTJo0qdw2Jk6cSO/evWnZsmWN46sOddPIaVHgLKXD49Mt2faGpwfi53XyPDs0NBQfHx8CAgKIjY2t8PzTTz9N//793Y8jIyPp2rWr+/Gzzz7Lt99+y5QpU9zfZiozcuRIbrzxRgCee+453nzzTZYuXcpll1120hhnzZrF2rVr2blzp7vy/fDDD+nYsSPLli2je/fupKSk8OCDD9KuXTsAWrdu7V4/JSWFa6+9ls6dOwPm4FiR41l1rm54eiABPtX7CDpT5+qtt97KddddR0hISLXO1VGjRrn/btGiBW+88QY9evRwz4T69ttvExoaymeffeb+gtCmTZtycd1///387W9/c5d17969Gkek8v3Pzs4mJCSERo0anXD/t2zZwhdffMHMmTO59NJL3fGXue2223j88cdZunQpPXr0wOl08tFHH/Hvf/+7xrFVl1pGRKqQnJxc7nFeXh4PPfQQHTp0ICwsjKCgIDZt2nTSb1tdunRx/x0YGEhwcHCFptyqbNy4kYSEhHLfAsu2v3HjRsC8A+7o0aO59NJLeeGFF8o1o95zzz08++yzXHDBBTzxxBOsXbu2WtsVqU/q6lwtS9qheufqqlWruPLKK2nWrBnBwcFcdNFFAO7trF69mt69e1c6o3FaWhr79+/nkksuqe5uVqmm+7969WocDgd9+/at9PXi4uK4/PLLmThxIgA//vgjhYWFXH/99acca1XUMiKnhb+3gw1PD7Rs2zVpAq7KH0faP/jgg0yfPp2XXnqJVq1a4e/vz3XXXUdxcfEJX+ePFZHNZsPlclUrBsMwKp1Q6PjyJ598kptuuompU6fy008/8cQTT/DZZ59x9dVXM3r0aAYOHMjUqVOZMWMGzz//PC+//DJ33313tbYvDV9dn6sul4uc7ByCQ4JPOC25v/ep3+m1jBXnal5eHgMGDGDAgAF89NFHNGrUiJSUFAYOHOjeTtlU6ZU50XOA+9gdX5dVNcNpTff/ZNsGGD16NLfccguvvvoqkyZNYvjw4ad15l4lI3Ja2Gy2ajfBng7VTUZ8fHyqPf35ggULGDlyJFdffTUAubm57Nq1q7YhVkuHDh1ISUlhz5497taRDRs2kJWVRfv27d3LtWnThjZt2nDfffdx4403MmnSJHecCQkJjBkzhjFjxvDII4/w/vvvKxkRt7o+V10uFyU+DgJ8vOr0Himedq5u2rSJ9PR0XnjhBfe5WTZwvEyXLl343//+h9PprJDoBAcH07x5c3755Rf69etX4fXLrvZJTU3l3HPPBSg3mPVETrb/nTt3xuVyMW/ePHc3zR8NHjyYwMBAxo8fz08//cT8+fOrte3aUjeNnNWaN2/OkiVL2LVrF+np6SdssWjVqhXffPMNq1evZs2aNdx0003VbuGorUsvvZQuXbpw8803s3LlSpYuXcqIESPo27cvycnJFBQUcNdddzF37lx2797Nr7/+yrJly9yJyr333sv06dPZuXMnK1euZPbs2eWSGJH6wtPO1aZNm+Lj48Obb77Jjh07mDJlCs8880y5Ze666y6ys7O54YYbWL58OVu3buXDDz9k8+bNgNmq+fLLL/PGG2+wdetWVq5cyZtvvgmYrRfnn38+L7zwAhs2bGD+/Pn83//9X7ViO9n+N2/enFtvvZVRo0a5B97OnTuXL774wr2Mw+Fg5MiRPPLII7Rq1YqePXue6iE7ISUjclZ74IEHcDgcdOjQwd3MWpVXX32V8PBwevXqxdChQxk4cCDdunU7rfHZbDa+++47wsPD6dOnD5deeiktWrTg888/B8wKIyMjgxEjRtCmTRuGDRvGoEGDeOqppwDzpnd33nkn7du357LLLqNt27a88847pzVmkdPB087VRo0aMXnyZL788ks6dOjACy+8UOFy2MjISGbPnk1ubi59+/YlKSmJ999/391Kcuutt/Laa6/xzjvv0LFjR4YMGcLWrVvd60+cOBGn00lycjJ/+9vfePbZZ6sVW3X2f/z48Vx33XWMHTuWdu3acccdd5CXl1dumdtvv53i4uJyA3VPF5tRF53rp1l2djahoaGkp6d7xO3pa8LpdDJt2jQGDx5c727LXpPYCwsL2blzJ4mJifj5+Z2hCKvmcrncI8vr463ArYj9RP/DsnMwKyuLkJCQMxbTqVC9UdGZOE917lnjdMT+66+/ctFFF7F3715iYmKqXK4u6g6NGRERERG3oqIi9uzZwz/+8Q+GDRt2wkSkrtSv1E9EREROq08//ZS2bduSlZXFiy++eEa2qWRERERE3EaOHElpaSkrVqygcePGZ2SbSkZERETEUkpGRERExFJKRkRERMRSSkZERETEUkpGRERExFJKRkRERMRSSkZETlHz5s157bXXqnx+5MiRXHXVVWcsHhGp3MnOVbGOkhERERGxlJIRERERD+V0Oq0O4YxQMiJnrffee4/GjRtXuLX4FVdcwa233grA9u3bufLKK4mJiSEoKIju3bsza9asU9puUVER99xzD9HR0fj5+XHhhReybNky9/NHjhzhjjvuICYmBn9/f1q3bs2kSZMAKC4u5q677iIuLg4/Pz+aN2/O888/f0rxiHi6M3WuLlu2jKuvvpro6GhCQ0Pp27cvK1euLLdMZmYmf/7zn4mJicHPz49OnTrx448/up//9ddf6du3LwEBAYSHhzNw4ECOHDkCVN5NdM455/Dkk0+6H9tsNt59912uvPJKAgMDefbZZyktLeX2228nMTERf39/2rZty+uvv14h/o8++ojOnTvj6+tLXFwcd911FwCjRo1iyJAh5ZYtKSkhNjaWiRMn1ugYnS5KRuT0MAwozrPmp5o3or7++utJT09nzpw57rIjR44wffp0br75ZgByc3MZPHgws2bNYtWqVQwcOJChQ4ee8PblJ/PQQw/x9ddf87///Y+VK1fSqlUrBg4cyOHDhwF4/PHH2bx5M1OnTmXjxo2MHz+eqKgoAN544w2mTJnCF198webNm/noo49o3rx5rWMROS3nqjO/zs5TOHPnak5ODjfccAPz5s3jt99+o3Xr1gwePJicnBzAvDPuoEGDWLRoER999BEbNmzghRdewOFwALB69WouueQSOnbsyOLFi1m4cCFDhw6ltLS02jEAPPHEE1x55ZWsW7eOUaNG4XK5aNKkCV988QUbNmzg8ccf59FHH+WLL75wrzN+/HgefPBB7rjjDtatW8eUKVNo1aoVAKNHj+bnn38mNTXVvfy0adPIzc1l2LBhNYrtdNFde+X0cObDc/HWbPvR/eDlf9LFIiIiuOyyy/jkk0+45JJLAPjyyy+JiIhwP+7atStdu3Z1r/Pss8/y7bffMmXKFPe3jprIy8tj/PjxTJ48mUGDBgHw/vvvM3PmTCZMmMCDDz5ISkoKXbp0ITk5GbvdXi7ZSElJoXXr1lx44YXYbDaaNWtW4xhEyqnjc9UOhFVnwUf3g09gtV7zTJ2rF198McnJyYSEhGC323nvvfcIDw9n3rx5DBkyhFmzZrF06VI2btxImzZtAGjRooV7/RdffJHk5GTeeecdd1nHjh2rte3j3XTTTYwaNapc2VNPPeX+OzExkUWLFvHFF1+4k4nnnnuOO++8k3vuuQe73Wxn6N69OwC9evWibdu2fPjhhzz00EMATJo0ieuvv56goKAax3c6qGVEzmo333wzX3/9NUVFRQB8/PHH3HDDDe5vOnl5eTz00EN06NCBsLAwgoKC2LRpU61bRrZv347T6eSCCy5wl3l7e9OjRw82btwIwJgxY/jmm2/o1q0bDz30EIsWLXIvO3LkSFavXk3btm255557mDFjRm13XaReORPnalpaGvfddx/t2rUjNDSU0NBQcnNz3a+xevVqmjRp4k5E/qisZeRUJScnVyh79913SU5OplGjRgQFBfH++++740pLS2P//v307du3ytccPXq0u7s3LS2NqVOnVkh4rKSWETk9vAPMbz5WbbuaTcBDhw7F5XIxdepUunfvzoIFC3jllVfczz/44INMnz6dl156iVatWuHv7891111HcXFxrUIzjsZls9kqlJeVDRo0iLVr1zJ//nxmz57NJZdcwp133slLL71Et27d2LlzJz/99BOzZs1i2LBhXHrppXz11Ve1ikekrs9Vl8tFdk4OIcHB7m/oVW63Bs7EuXrbbbdx8OBBXnnlFRITE/H19aVnz57u1/D3P3GL68met9vt7jqgTGUDVAMDy7cYffHFF9x33328/PLL9OzZk+DgYP7973+zZMmSam0XYMSIETz88MMsXryYxYsX07x5c3r37n3S9c4UJSNyeths1W6CPS2qmYz4+/tzzTXX8PHHH7Nt2zbatGlDUlKS+/kFCxYwcuRIrr76asDsl961a1etw2rVqhU+Pj4sXLiQm266CTAro+XLl3Pvvfe6l4uKimLkyJGMGjWK3r178+CDD/LSSy8BEBISwvDhwxk+fDjXXXcdl112GYcPHyYiIqLWcclZrK7PVZcLvEvN1zxRMlJDZ+JcXbhwIf/+978ZPHgwdrudPXv2kJ6e7n6+S5cu7N27ly1btlTaOtKlSxd++eWXcl0qx2vUqFG5cRvZ2dns3LnzpHEtWLCAXr16MXbsWHfZ9u3b3X8HBwfTvHlz5s2bx+WXX17pa0RGRnLVVVcxadIkFi9ezG233XbS7Z5JSkbkrHfzzTczdOhQ1q9fz5/+9Kdyz7Vq1YpvvvmGoUOHYrPZ+Mc//lFhRH9NBAYG8te//pUHH3yQiIgImjZtyosvvkh+fj633347YA5ea9++PcnJyTidTn788Ufat28PwKuvvkpcXBznnHMOdrudL7/8ktjYWMLCwmodk0h9cbrP1VatWvHFF1/Qu3dvcnNzefDBB8u1OvTt25c+ffpw7bXX8sorr9CqVSs2bdqEzWbjsssu45FHHqFz586MHTuWMWPG4OPjw5w5c7j++uuJiori4osvZvLkyQwdOpTw8HD+8Y9/uLuZThbXBx98wPTp00lMTOTDDz9k2bJlJCYmupd5/PHHGTt2LAkJCe5Bt7/++it33323e5nRo0czZMgQSktL3VcheQqNGZGz3sUXX0xERASbN292t1aUefXVVwkPD6dXr14MHTqUgQMH0q1bt1Pa3gsvvMC1117LLbfcQrdu3di2bRvTp08nPDwcAB8fH55++mnOOecc+vTpg8Ph4LPPPgMgKCiIf/3rXyQnJ9O9e3d27drFtGnTTtwcLtJAnO5z9b///S+ZmZkkJSVxyy23uC/BP97XX39N9+7dufHGG+nQoQMPPfSQ+2qZNm3aMGPGDNasWUOPHj3o2bMn33//PV5e5vf+Rx55hD59+jBkyBAGDx7MVVddRcuWLU8a15gxY7jmmmsYPnw45513HhkZGeVaSQBuvfVWnnvuOcaPH0/Hjh0ZMmQIW7duLbfMpZdeSlxcHAMHDiQ+3qILDKpgM/7YgeWBsrOzCQ0NJT09ncjISKvDqRGn08m0adMYPHgw3t7eVodTIzWJvbCwkJ07d5KYmIifn98ZirBqLpeL7Oxs96j4+sSq2E/0Pyw7B7OysggJCTljMZ0K1RsVnYnzVOeeNaoTe35+PvHx8UycOJFrrrmmzrZdF3WHumlEREQaMJfLxYEDB3j55ZcJDQ3liiuusDqkCpSMiIiINGApKSkkJibSpEkTJk+e7O428iSeF5GIiIjUmebNm1e4pNjT1K9OMREREWlwlIxInfL07Fuqpv/d2UP/a6lLdfF+UjIidaJsxH9+fr7FkUhtlc0yWZ15D6R+0nkqp0PZ++lUrvzSmBGpEw6Hg7CwMNLS0gAICAioMOX5meRyuSguLqawsLBeXqJ3pmN3uVwcOnSIgIAAjxzcJnXjTJynOvesYUXshmGQn59PWloaYWFhp/RFRrWO1JnY2FgAd0VnJcMwKCgowN/f39KkqDasit1ut9O0adN6d7ykZk73eapzzxpWxh4WFuZ+X9WWkhGpMzabjbi4OKKjoyu9+dOZ5HQ6mT9/Pn369KmXk81ZEbuPj0+9+zYoNXe6z1Ode9awKnZvb+866dpVMiJ1zuFwWD7uwOFwUFJSgp+fX72rVOpz7FJ/nK7ztD6/fxW7dfQ1SERERE4oPbeIR79dx9S15l2Hf9uRwSPfrGXP4YqDoV0ug1dmbOb9+Tuq/fpqGREREalH9mcWEBnkg6/XmWmBLnSWcscHy1mVksknS1L4akUj5m05hMuATQdy+HpML+z2Y+NUXpy+mXfnbQegbWSnam1DyYiIiEg9MW1dKmM/XklEoA/XJTVhTN+WRAT6nHCdrAInMzccpHPjUNrGBrvLtxzM4fd9WQztGo+3o/KOEpfL4JFv1rEqJRN/bwcFzlLmbD4EgN0Gq1Iy+XhpCq0aBfH7viwOZhfy34U73euPn7u9WvulZERERE7okyUpZBU4GdO3Rb27yqQhKSl18e/pmwE4nFfMf+bvYOraVN67JYm20QEVli91GTw7dQOfLk2h0OnCx8vO01d0xMfLzidLUli++wgAuzLyGde/DT+s2c/iHRkM6RJHzxaR5BaVMO6LNczccBCH3cb7I5LJLSph/NxtXJvUBJfL4MkfNvCP736vsO3rk5rwzap9/Loto1r7pmRERESqtDM9j0e/XQdA3zaN6BBf9W3gpWqZ+cV4O+wE+lb+sWsYBs9O3ciCrYeYcGt3EiIqJhdT1uxnZ3oe4QHe/PPqzrz48yZ2ZeRz7fhFTB6ZBEBRiYs8ZzFhAT589NtuJv26C4DIQB8y8op5+Jt1FV73kyUpDEtuwgNfrqGoxMUnS1Lw93ZQahgUl5hJzL+v68KFraMAuKyTeRlvqcvg29X7WbMnk0AfB33bNsLPy0GnxqGM7NUcgM8XbanW8VEyIiIiVfrot93uv+dvPXRKyYhhGCzclk6T8AASowJPKS5nqYsf1+7nglZRRAf7ndJr1bVSl8Gi7en4OOyc1yKSfZkFDHx1PiUuF0O7xHPXxa1oFll+/99fsIMJR7s3Hv12HR+M6sHiHRnkFZVyUdtG5BeX8ubsbQDc0acFgzvHcUGrKO76ZCULtqbz6Lfrua05XPnOYlIO53PvpW3cXST/d3l7Rl2QyJuzt/HaL1uID/Xnxh4JXN2tCde88ysHs4sYOWkZRSUuYkP8yCl0kldcCkB8qB/j/5RE14SwCvvpsNv4323dWbbrCD1bRhL0h0Tr7otbM3WlumlEROQUFBSX8uXyPe7H87ccYkzflgDsyyzgrdlbadkoiMs6xbJwazrLdx9hxHkJGAZ8tXIfa/dlM7RrPD1bRGKz2Zi8aBdP/bCBQB8H34y9AIfdxoSFO7i8c7z7W3d1vTxjC+/O206LqEC+HXsBv+/PYuaGg4zt1/KMJyeZ+cV8vXIfS3dm4DJgw/5s9mUWYLfBjPv6MmdTGrlFJQB8uWIv87YcYspdF7I/q4DJv+4ir6iE2ZvNSejsNliwNZ3bJi9j7tGxGVFBPuQWlVDodBEe4M2Ins0BCPX35q2bunHpK/PYmZHPv7Ic5JXkAbi7c85JCGPUBYnY7Tb+dmlrRvZqTpCfF46jA05v7NGU12ZtZVtaLgAvXd+VpGbhpOUUAhAf5l/leBKAsAAf+neIqfS5ppEB/DLuIuJfOPkxVDIiInIWyCsqwWUYBPtVfw6KKWv2kV1YQliAN5n5TpbvOkJ+cQlr92Zx58crycgz72f07NSN7nV+XLufFoF2Nvy2HoBPl+4hMSqQS9pFM/FX85t/XnEpIyctJaewhNyiEj5btocHB7blr31bYrPZcLkMsgudhAVUPjBz04Fs/rvAvGx0R3oeV4//lZ3peRiG2a00+bbutRrb4ix1kV187HFOoROXC0IDqj5mX63Yy2PfrqOoxFXhOZcB363ax5Kd5riJW85vxm87MtialssN/1nMvswCnKXHbjJ303lNiQ3x45WZW9yJSFiAN+m5ZlBtY4J5fGiHci0Qof7ePDG0A3d9soq8EhsBPg5u6tGUCb/uxGGz8dzVnctd6fLHfbmxR1PenL2NUpdBcrNwLmhlJo5/bLmpraq6pf5IyYiISAOXX1zCwNfmU1ziYsZ9fdwf8sUlLmZsOEBSs3DiQv3dy6dk5PPu/O18v2ofAH/t25IPf9vN3iMFvDJjC5MX7aLEZdAuNhgvh43f92XTPDKAqCBflu8+woZMO3YbXNo+hkXbM9iZnue+wmJo13jW7s1kd4Y5P0XjMH/2ZRbw4s+bycp3cl//NtwyYQlr9mTx1k3nMqBj+WnGswudPPLNOkpcBt2bh/P7vmx2HDJbA2w2mLflED+uTaVRsC8bU7PLrdu9eQSdGodWeZz+7/sNfLPKiy8P/kbTiEBmrD+In7edL8f0ok1MELM2ppEYFUCraPOKlEXb03n467WUuAzax4Vw9bnxBPt5Ex7gTW5RKQ98uYYvlu/hUG6ReRwvaskdvVtw5dsL2XV0/wd2jOGittE0CvKlX7toSlwuftl4kG1pufzrui4M7BjL4u0ZBPt5cU5CWKVJ1uWd4/i+/T5mbzrIK9d15rIujbk+OQGXYcZ1IjEhfgxLTuDrFXt56LJ2lg1QVjIiItLAfbjYTCQAJizcyf0D2pKWXchfP17Jit1HCAvw5s0bz6V360bM3nSQv322mpxCs1uhS5NQbujRlN2H8/lkSYo7qbisYyyvDj8Hfx8HmfnFhPh5YwCvztjEd8u288x1yfRrH0teUQk/rNnPVyv2EhPqx0vXd2HP4QIe+moN3ZtH8MDAtny6NIXHv1/Pe/N3sHBbOuv3m0nEvZ+v5tXh57Bi9xFSMvJxlrpYtD2DAmcpgT4O3rjxXDYdyOHlGZu5qUczDmYX8vovW7nns1VUdld7uw0eGdSe0b0TK3zo7s8s4LvV+wFYuzebtXvNGIpLXdz+v2V0ig/l5/UH8PGy88yVHQny9ebRb82k6Iqu8bx+wznlXrOguJQnvv+dtBwzEencOJT4MDPhe39EMk//uIHBneP4S5/yVyg57A6+HNMLA8M9j0ifNo1O+P+12Wy8eUNXvv3xJy5pHw1Q7hLek3n2qk48OrhdjVrN6pqSERGRBsAwDPYcLqDAWUrK4Xw+W5pCyuF8HhncjveOmwlz8q+76NYsnL9/tdb9QZmZ72TExKWE+pvdMQBJzcJ5YEBbzm8Rgc1mo0/rRnyyJAWAc5uG8doN5+DnbX5YHt+d8rdLWtG6aAsXtooEzGb6G3o05YYeTd3LtIoO4puxF7gfj+jZnPScIt6YvY31+7PxsttoGxvM+v3Z/OXDFRX2tVV0EP93eXviQv2JC/WnX1vzA7jQWcoPa/ez41AegT4OLmwdhc/RD/SM3CIWbc/gn9M28sbsrfh6Obg+uQn392+Dl8POp0tTcBmQGGwwrFdbjhSU0LdNIx79dh27M/LdyVxxiYu/f33sipSuCWG8eF2XCsmNv4+DgZ1i+Wal2bo04LhxFcnNI5hy14VV/i99vGo+ObrDbiOglp/oDrvN0kQElIyIiDQIH/62m8e/X1+hfNTk5QA0iwzA39vBpgM53DZpGQBtYoJ488ZuTFi4gy+W73UnIn86vymPD+lY7kPxwtZRRAX5Eujr4L1bktyJSF2599I27DlSwA9r9vPsVZ0Y1CmO695dxI70PC5pF03v1lHYbDbaxQaT1Cy80u4EP28Hn95xPqtSMundOqrceAXDMPjwt9088+MGcgpLyKGE8XO3s3ZvJs9c2YlPl5oDdS+KczH6wubu+7tMuDWZYe/9hpfdxjs3d2PhtnRe/2UrjYJ8GZacwB29W1R5LK4+t/GxZKTjqd3VtqFTMiIiUs8YhsGSnYf5aV0q/dpF07t1I/5ztPUj1N+bYD8vBnWK5VBOkbvr4e6LWxPk62DMRysBs5vlpWFdCfL14sXrunLvpW3ILy4hyNeb2NCKV6ME+Xqx4KF+2GzUeSICYLfbeHX4OTx9ZUf3t/Qf7r6Q4lIXITX41h4T4ueeB+N4NpuNET2bM7RLPBl5Rfy+L5tHv13Hr9syuPjleea6wb50Ds8rt16r6GAWPNQPHy873g47yc0juOX8ZoT6e+N1gqtMAHq1jOLyLnEE+jhoExNU7X04GykZERHxINmFTvxP8FmfVeDklglLWLs3CzAvFX10cHv2Hikg1N+bJY9e4k4WDMOgT5tGpGYVcvW5jbFhzjkR6OvFDd0TyrUulI1nOBF/n9N/L5Tjuwv8vB11nviEB/oQHuhDq+hgOsSH8MyPG1iwNR2AG3sk4MjfVGGdP14REhnkW61tOew23r6p26kHfRao1V1733nnHRITE/Hz8yMpKYkFCxaccPmPP/6Yrl27EhAQQFxcHLfddhsZGdWbIlZEGgbVGyeWV1TCnR+vpMuTM5i82Jxo7EB2IXM2p+FyHRuN+e/pm1i7N4sAHweNw/zJLy7l/45Oxz0suUm5D2+bzcY13ZpwZ79WOOw27HYbo3u34MYeTTWtO9AmJpgPbz+PeQ9exPibu/GX3s2tDumsVeNk5PPPP+fee+/lscceY9WqVfTu3ZtBgwaRkpJS6fILFy5kxIgR3H777axfv54vv/ySZcuWMXr06FMOXkTqB9UbFRmGweLtGTzyzTru+mQlQ99cyNR15u3ZX5qxlW3ZcO27S7ht0jL+8tEKcgqdrEw5wsdHB5H+99ZkJo7sjtdxc0j86fxmluxLfdcsMpBBneNO2u0ip0+Nj/wrr7zC7bffzujRo2nfvj2vvfYaCQkJjB8/vtLlf/vtN5o3b84999xDYmIiF154IX/5y19Yvnz5KQcvIvWD6o3yNh/IYdDrC7jx/d/4dGkKP65NZUd6Ho2CfenSJJSiEhdvrXe4r3aZueEgPZ+fzc3vL8Ew4NpuTejVMoq2scH8uU8LAC5uF11nE1WJnGk1GjNSXFzMihUrePjhh8uVDxgwgEWLFlW6Tq9evXjssceYNm0agwYNIi0tja+++orLL7+8yu0UFRVRVFTkfpydbV7v7XQ6cTqdNQnZcmXx1re4QbFbxRNjP5VYVG8cU+oy+HHdAR6fsoH8YnOujCFdYmkdHYSPl53+7aPJLSrh8jcXU1xqTv391ND2PPfTZg5km/vWKMiHhwa0cu/TPf1a0D42iB7Nwz1iPz3x/Vtdir3uVTeeGiUj6enplJaWEhNTfh76mJgYDhw4UOk6vXr14uOPP2b48OEUFhZSUlLCFVdcwZtvvlnldp5//nmeeuqpCuVz5swhIKDinQzrg5kzZ1odQq0pdmt4Uuz5+fm1Xreh1xtFpfDzHjudIly0rGKyS8OABQds/LLfTmax2a3SOsTFyDYlBHnvBvNO7iw1ZwDnyqY25qXauTGxACNlJQ+2h4PmNBeE+5bw27xZFbZx3P3sPIInvX9rSrHXnerWHbW6muaPA58Mw6hyMNSGDRu45557ePzxxxk4cCCpqak8+OCDjBkzhgkTJlS6ziOPPMK4cePcj7Ozs0lISKBfv35ERkbWJmTLOJ1OZs6cSf/+/d3XrdcXit0anhh7WSvDqWio9cb4eTuYnbqN3zK8+Wx0D9rHlZ/5Mq+ohEe+Xc9Puw4CEObvzS3nJzC2b4sqxyj098D3QHV54vu3uhR73atu3VGjZCQqKgqHw1Hh20xaWlqFbz1lnn/+eS644AIefPBBALp06UJgYCC9e/fm2WefJS4ursI6vr6++PpWvHTK29vbow5yTSh2ayj2unEqcTTkeqOk1MVny/YCkF9cypiPV/H9XRfSKNiMY3dGHn/5cAWbDuTg7bDx8KD23Hxe02pfrupJ74GaUuzW8LTYqxtLjZIRHx8fkpKSmDlzJldffbW7fObMmVx55ZWVrpOfn4+XV/nNOBzHroEXkYatIdcbv2xKY39WIeEB3oQH+LAjPY+/fLicT+44nyU7D3PPp6vIKnASFeTLu3/qRnLzCKtDllOVfxim3A2dr4eOVx0rX/8tLHoLjNJjZY3awdA3wOWE7++EI7vAZofuo+GcmyBlCcx8HEqL/riVY5p0h8v+BfYTX29iW/s53XdMhLzuEBZ/SrtohRp304wbN45bbrmF5ORkevbsyX/+8x9SUlIYM2YMYDaV7tu3jw8++ACAoUOHcscddzB+/Hh3c+u9995Ljx49iI+vfwdMRGquodYbHx0dqDG8e1OGJTfhqrd/ZWVKJsPeW8zv+7JwGXBOQhjv/imp0llNpR5aPhE2/QjbZ0P8uRDeDLL2wvd3QXFu+WX3r4Ko1lCQaSYrZQ78DrFd4Js7IPMkg332rzKX7XZL1cukb8Mx7T7iS4txzXgEhv2v1rtnlRonI8OHDycjI4Onn36a1NRUOnXqxLRp02jWzLy+PTU1tdzcASNHjiQnJ4e33nqL+++/n7CwMC6++GL+9a9/1d1eiIhHa4j1xlcr9rJgazo2G9x8XlMSIgJ45+Ykbp201D076vDkBJ6+qqP77qvSAGyaav525sO0B+CmL+Cnv5uJSONk6Pt38/kDa2D2szD3X+Ay74DMwOdhy0+wcz5MHGiuE9IEhrwCVDJ+auc8WPwWzPg/aHMZBFVy917DgB/vxVZaDIB9w3ewdSa07l/nu3462QxPavOsQnZ2NqGhoaSnp9fLAazTpk1j8ODBHtWPVx2K3RqeGHvZOZiVlUVISBWXjHiY01VvGIbBMz9uZOKvOwG4oXsCL1zbxf38l8v38PacbdzeuwV/Oq92M5164nuguuok9hX/g5X/Mz9oayMoBq4eD/7h5csLMmHag9DiIjj3ZkjbaD4uNu9H4zIMsrKyCA0Nxf7H/1uLvtD9Dni1A2ADhzeUFkN0R0hbD3Yv+MsCiOlgLm8Y8MGVZkIB0OFKGPYBHN4B7/SEkkKz/IZPod3gyvejtATevwgOrIOwphAQVckyxXDwdwwvf/YFdaFJ5hLwC4OIFpW/pt0Leo+DtoNOfAzrSHXrDt2bRkSkBt6cvc2diPztktb87ZLW5Z6/PjmB65MTrAitYUjbCFPvN8dZnIrVn0LPseXLZj0B676ALdOhyzD49Q3Ydey2BHYgHKCyq1H3rzS7VwASekDLS2Duc2YiAnDB344lIgA2Gwx5Fd69EBw+5rgPMJOEfo+aY0U6XFl1IgLg8IKhr8N/+0NmivlTBVefB1md3oTGxn5sWXvMeKsy68kzloxUl5IREZFqMAyD71fv55WZWwD459WduPk8Tb9ep1wu+PE+MxFpeQn0+HPNX2P7bFj6ntmdcnwykvIbrJhs/l2UBTvmmV0mYHafRLSgpLSE5cuXk5ycjJfjuI/HLT/Dikmw7egcHu0uh553Q7OeUJwP3v7QvHfFWCJbwtjfzNaIkOOuAOt1DzS7EGI7nXx/GifBX3+FIycYW+IbhCu+B6U//UTJyOl4p62rfDmXE74cCYc2Qfo2iGp18u2fIUpGRERO4peNB/n39M1sOpADwG0XNOfmcyLgmz+bVzv0uOPkLzLv35C9Fwa/BKVOmHJXlR8wDsOgd2YmjoOvm9+wj9ckGS57oWJ5fZJ7yNz/vPTy5SWFcPB38A40WwTCatHCFN3eTEZSFkFeBgRGQkkx/HCv+bzD17x6ZdYTUHAEAiLNpMfhheF0cnBrKUbrgXB8F1OLvrBjLhwxW8RoN8S8uiWxz8njCa8kYbXZoElSzfYpuv2Jlymb6TQoGsIvq3q55r1hxxzYPBWyu8LcF8z3Y0AEXPGm2cU15zkoOGy25jjOTJqgZERE5AQMw+Dhb9ZxKKcIP287N3RvymOD28OMR2Dt57D2C2jczfwGW5Ut02HOs+bf4c3NsQu/f13l4nYgAirvLti33Ly64tyba71PlvvpIbO1oSoX/1/tEhEwP/xjO5vjLLb8bB6nxW/CoY3mmIuB/4Rv/2ImPQBtBp38A9fb3+xy+egaiDvHbPGor9pdbiYja7+ExW9D7sFjz017ADoPg/kvmo8jWlbs6jpNlIyIiJzAnsMFHMopwtthY/HDlxAe6AP7VsCS944uYcAPf4M75lb+oVacZ46BKDP3hWNXVwz4Z6UfbCUlJSxfsYLkpKTy863sXAC/vX3s6orA+jWgHzCv9Fj/jTnfxhVvmd/Ij+cbDM0uOLVttBtiJiObpppdKfOOfrgOfM4cp/HjOHDmHV226vsdldOyH4xdAoGVDCKtT9oONpOOg0e7ciJbQZ8HzXlQNv4A2+ceW3b2s9DhCghtctrDUjIiInICK1IOA9CpcSjhy141xw0c2Q0Y5rfqlMXmB9+Sd6HXXRVfYO7zkLUHQpuaV0TsXmiWt7+i8uXB7C7Y5sJoc1n57oJWl5qXhR5cB/+9GAKPXupp9zIHUFY2KHHx23Bwvdk95HP0Hj0FmebEXTmptTsoJ+AwDHofOYIj7Y3Ku5Iytpm/zx97+lp32l1uHvetMyB1tdn9k9jXHLRqs0HrS2HD9+AdYCYZ1dWozemJ90wKbQzx3Y4NcB3yGiT2NseRLHwVinPMQbaBjWDPEph4GQTHQefr4Ly/HHud3YvMZOXoJcVVKiipVlhKRkRETmDFbvMudv1ii82rJ8r4h8MVb5hdAVPuhjn/NL9FhjU9tkzqWlj8jvn35S+brSDjLzCvrhhUizlTHN4w9DWYMMCczfPIrmPPpW2Eu5aXn4ti9yKY/qj5d1A0XPqk+fesJ2HjlJpvvxpO2MVUJrQpXPTIadk+ADGdzNlPD22C7H3gdbSbpSw56nKDmYy0v8LsgjnbdBluJiPn/slMRAD6PGQek8M7zWMVFAPv9TET6aw9sHeZOV6pcRIU5cLXd5hjoE6mqHqXZysZERE5gRW7MwG4xL7CLIjtYn6QxnYyP+DP+ZN5GWnKInPOihs/Mz/0XKXw473m9OAdroI2A8z1xy4+enVFLWeSbZIMYxaUH/w69zmzdWbG/8E1R7uPSorNK1PKLHrTHA9QnGteGQJmghRctzPalpSWsGLFCpKSkspfkXK8xkngG1Sn2y3HZoNbf4C9y83HUW3Kd4e1G2zOCVKfx36cih5/Nv8HjbsdK/MJgNtnQt6hY4NlxyyEjO2w+mNz1tkf7oU75pitTtl7zcT7sheodMK2Mrn58ML1Jw1JyYiISBVyCp1sPmDedbT14aOTV3UZVn5uCLv92HwSW36G9/uB3ducofPg7+AbcrTCPioi8dQDi+lo/pQJioH/XgJrPzO7QWx2KMoxWwYCoiCuK2z/xRyAWTZe5Zw/mfdIqWOG08mBbQZGm0Hlu5jOtKDoE8/hEdel6ucaOrsdErpXLA+MKj8mplFb86dJd9i1EA6sNVtLDm00n7/8lZPP9FrNu/ae+M47IiJnKcMwWL0nE5cB7cNL8dm7yHyibSUfcNHtzFktwbyXyN6lx67WuPSJ8nNMnA5Nko715+9bbm6/7APjshfM7iTfEHOMSN4hM0Hp//TpjUkajqBGMODo1WBp68FwQadr63TKebWMiIj8wUe/7eYf3/9OdLAvADeFbYTUEojuUHXTft+HoWlPs0WkjF8YNOt1+gMG88OidX8oOe4OsAFR0PQ88++/zIe0DebfcV3r55U4Yp1ut5hX3hQcNlv+EiuZ5O0UKBkREfmDj5ekYBhwMNv8YO/jWmo+caLLQO32ml2ZUdcc3ubVNlWJSKybLiI5ezXredpeWsmIiMhx0nIK2Zhq9nP/pW8LDucWk7Bzjflk6wEWRibScCkZERE5zoIt5hTlnRqH8Mig9pB/GF48ZD4Z3eEEa4pIbWkAq4jIceZvNROPPq2PztdRNklXSOPTezmqyFlMyYiIyFEul8GCrWbLSJ82R5ORdPMuvUS1tigqkYZPyYiIyFHr92dzOK+YQB8H3ZqGm4XuZKQBTAUu4qGUjIiIHLVwm9kq0rNlFD5eR6vH9K3mbyUjIqeNkhERkaNWpZj3oTkv8bg7yaqbRuS0UzIiInLU2r1ZAHRpEmoWlBSbNw4DtYyInEZKRkREgIPZhRzILsRug06NjyYjR3aaN7rzCTJvoy4ip4WSERERYM2eTABaRwcT6Ht0Cqbju2hsJ7gzqYicEiUjIiJU0kUDupJG5AxRMiIiAqzZmwlA14SwY4XuK2k0eFXkdKpfyUip0+oIRKQBMgzD3TLStUlYWSHsWWL+rWngRU6repWMGDvmWx2CiDRAuzPyySpw4uOw0zY22Cw8tAkO7wCHLyT2sTZAkQauXiUjeSs/tzoEEWmAlu46DED7+JBjk51t+tH83eIi8A22JjCRs0S9SkZC9swx76ApIlKHPluaAsAl7aKPFW6aav5ud7kFEYmcXepVMuKgBNZ/Y3UYItKA/L4vi5UpmXjZbdzQI8EszNoL+1cBNmg7yNL4RM4G9SoZATCWTzYHlomI1IGPftsNwGWdYokO9jMLN00zfyecB0HRVawpInWlXiUj+YYPtoPrYNsvVociIg1AVoGT71bvA2BEz+bHnigbL6IuGpEzol4lI1+W9jX/WPCytYGISIOwYOshCp0uWkUH0b15uFlYcAR2LTT/VjIickbUq2TkfyUDKcELUhbB7sVWhyMi9dyK3eZdei9oGYmtbLr3LTPM+9E0ag+RLS2MTuTsUa+SkTTC+bK0t/ngt3esDUZE6r2VR5ORbs3CjxWqi0bkjKtXyUhS0zA+KBlgPtjyMxRkWhqPiNRfBcWlrN+fDUBSWTLiLDg2Jk3JiMgZU6+Skcu7xLLRaMpOe1MoLYaNU6wOSUTqqbV7M7G7inkj4L80/uFG+OBKmDwEnHkQHA/x51odoshZo14lI5e2i8bXy8EXRb3MgrVfWBuQiNRbK1KO0M++mitcs7HtmAs75sK+5eaTna6BsjEkInLaeVkdQE0E+3kxsGMsU9b05O/en5kj3rP2QWhjq0MTkXpm5e4jdLNvNx+0vBi63mj+7eULrfpbF5jIWahetYwAXH1uY/bRiJW0BwzNyCoiNZZbVMKK3UfoajuajHS4EroMM386XAk+AdYGKHKWqXfJyAWtoggL8GaKs7tZoAnQRKQGXp25hR7/nEVmfhFd7DvMwsZJ1gYlcpard8mIj5edyzrG8qurk1mQshichdYGJSL1wuG8Yl7/ZSv5xaX0icwi2FYAXv7mnCIiYpl6l4wADO0az1ajMYcIg5JC2LvU6pBEpB5YszcTgBZRgUzu7zAL47qAo14NnxNpcOplMnJeYgRRQb4sLO1oFuyYZ21AIlIvrN2TBUDXhDBs+1eZheqiEbFcvUxGvBx2BnWKO9ZVs2OupfGISP1Q1jLSpUko7FthFsZ3sy4gEQHqaTICcFHbRvxaejQZ2b8SCrOsDUhEPJphGKw9mox0jQuAA+vMJxorGRGxWr1NRs5rEckhexQ7XLFguGDXr1aHJCIebH9WIem5xXjZbXT02gelReAXChEtrA5N5KxXb5ORIF8vzm0axm+uDmZByiJrAxIRj7Z2TyYAbWOD8T14dLxIfDfNtCriAeptMgLmnCPLXW3MB3t0RY2IVG3NXrMrt0uTMLNrF9RFI+Ih6nUy0rt1FCsMMxkx9q+CkiKLIxIRT7XmaMtI1yahsE9X0oh4knqdjHRpEkaGT2MOGSHYSoth/2qrQxIRD2QYBr/vP3pZb4wPHNpoPqEraUQ8Qr1ORrwdds5vEclKd1fNEmsDEhGPlHI4n5zCEny87LR2bTMHvQfHQUic1aGJCPU8GQHo2iSMFa7W5gMlIyJSifX7swFoGxOMV+pqs1BdNCIeo94nI50ah7Li+EGshmFtQCLicdYf7aLpGB9y3GRn51oYkYgcr94nIx0bh/C7kUiR4QV5aXBkp9UhiYiHKWsZ6RgfoitpRDxQvU9GooP9CA0OZoPR3CzYt9LSeETE85QlI50aecGRXWZh3DmWxSMi5dX7ZASgc+NQfnc1Nx8cWGtpLCLiWdJzijiUU4TdBu38M81Cv1AIiLA0LhE5pkEkIx0bh7LBaGY+KLvfhIgIsOlgDgAtGgXhn7fPLAxramFEIvJHDSIZ6RQfwgbX0WQkda0GsYqI2+YDucDR8SKZKWZhWDMLIxKRP2oYyUjjUDYZTSk1bJCfDrkHrQ5JRDxEWcuImYzsNgvVMiLiURpEMhIX6kdQYBDbjXizIFXjRkTElJpVCEBiVNBxLSNKRkQ8SYNIRmw2G+3igo8bN6JkRERMzhIXAP7eDiUjIh6qQSQjAK0aBR0bN6JBrCJyVNHRZMTX265kRMRDNZxkJDqI9WVzjSgZEZGjypIRf6MA8jPMwtAECyMSkT+qVTLyzjvvkJiYiJ+fH0lJSSxYsOCEyxcVFfHYY4/RrFkzfH19admyJRMnTqxVwFVpGR3ExrKWkcPboSinTl9fRE6NVfVGUUkpAIEFqWaBXyj4h9X4dUTk9PGq6Qqff/459957L++88w4XXHAB7733HoMGDWLDhg00bVp50+ewYcM4ePAgEyZMoFWrVqSlpVFSUnLKwR+vVXQQhwnhgBFOrO0IpG2EhB51ug0RqR0r642iUrNlJCBfc4yIeKoaJyOvvPIKt99+O6NHjwbgtddeY/r06YwfP57nn3++wvI///wz8+bNY8eOHUREmDMeNm/e/NSirkSjIF9C/LzYUtqEWMcROLRZyYiIh7Cy3nCWGODFcROeaY4REU9To2SkuLiYFStW8PDDD5crHzBgAIsWLap0nSlTppCcnMyLL77Ihx9+SGBgIFdccQXPPPMM/v7+la5TVFREUVGR+3F2tnlfCafTidPprDK+lo0C2ZbamD6so/TgBlwnWPZMKYv3RHF7KsVuDU+M/VRisbzeKDWwe4Ej25xjpDSkiUfUDSfiie+B6lLs1vDU2KsbT42SkfT0dEpLS4mJiSlXHhMTw4EDBypdZ8eOHSxcuBA/Pz++/fZb0tPTGTt2LIcPH66y//f555/nqaeeqlA+Z84cAgICqozPp9DOVqOxGevGhfxWPK26u3bazZw50+oQak2xW8OTYs/Pz6/1ulbXG2UOb1tBILBhXy47pnlO3XAinvQeqCnFbg1Pi726dUeNu2nAnNfjeIZhVCgr43K5sNlsfPzxx4SGhgJmk+11113H22+/Xem3nEceeYRx48a5H2dnZ5OQkEC/fv2IjIysMq59C3cye8YWAKJtRxg8eHCN962uOZ1OZs6cSf/+/fH29rY6nBpR7NbwxNjLWhlOhVX1RpnG/k7Igva9BtKuzaBT3p/TyRPfA9Wl2K3hqbFXt+6oUTISFRWFw+Go8G0mLS2twreeMnFxcTRu3NhdoQC0b98ewzDYu3cvrVu3rrCOr68vvr6+Fcq9vb1PeJDbxobyn6MtI7asPXi7isA3qFr7drqdLHZPptit4Umxn0ocVtcbAIF2J/YM84uKV6PW4CHH9WQ86T1QU4rdGp4We3VjqdGlvT4+PiQlJVVoBpo5cya9evWqdJ0LLriA/fv3k5ub6y7bsmULdrudJk2a1GTzJ9UqOohMgkk3jlZg6Vvq9PVFpOY8od7o67UenPkQ0hgatavx+iJyetV4npFx48bx3//+l4kTJ7Jx40buu+8+UlJSGDNmDGA2lY4YMcK9/E033URkZCS33XYbGzZsYP78+Tz44IOMGjWqyoFotdUkPAAfLztbXWbrCIc21+nri0jtWF1vDHCsMP9odzlU0TUkItap8ZiR4cOHk5GRwdNPP01qaiqdOnVi2rRpNGtmXi6XmppKSkqKe/mgoCBmzpzJ3XffTXJyMpGRkQwbNoxnn3227vbiKIfdRouoQLamN6YnG+DQpjrfhojUnJX1hh0XfY1l5oN2Q+pkf0SkbtVqAOvYsWMZO3Zspc9Nnjy5Qlm7du3O2AjfVtFBbD2klhERT2NVvdHVto1wssEvDJpV3i0kItZqMPemKdMqOohtRlkyopYRkbPdxY7V5h9tLgOH5wzsE5FjGmQystV1dIDbkV1QnGdpPCJirST70RbSNgOsDUREqtQgk5F0QjlIOGBA6lqrQxIRC8Xajph/RLSwNhARqVKDS0aaRwZit8Hq0pZmwb7l1gYkIpaK5OikS8Fx1gYiIlVqcMmIn7eDhIgAVrtamQX7VlgbkIhYymEzKMUOgY2sDkVEqtDgkhGAVo2CWG0cbRnZq2RE5GyX7RUJdofVYYhIFRpmMhIdxDpXIi5skJUCuWlWhyQiFsr2irI6BBE5gQaZjLSMDiKXAPZ7Hb1J1r6V1gYkIpbK8VEXjYgna5DJSKto8+Z4q10axCoikO8bbXUIInICDToZWVyUaBZoEKvIWS3fVy0jIp6sQSYjIX7exIf6HbuiZs9SKMo98Uoi0mAV+sdYHYKInECDTEYA2sWFsN5oRnZAUyjOhfXfWh2SiFikKEDJiIgna7jJSGwwYGNR6GCzYOX/LI1HRKzjVDIi4tEabjISFwLA587eYPeCvcvg4AaLoxIRK5QGxlodgoicQINNRtrHBgOwNM0Lo80gs1CtIyJVKykGw7A6ijqXa/ji8A+1OgwROYEGm4wkRgXi47CTV1xKepvhZuGGKQ2yshU5ZVtnwr9bwcfXm0lJA5JmhOHr1WCrOpEGocGeoV4Ou/sS3zVencHhCzn7IX2rxZGJeJgt0+Gzm6AoC7bNhGkPwI658POjsOhN2DkfSkusjrLWDikZEfF4XlYHcDq1iwtmQ2o2Gw45ubTp+bBznlnJNmpjdWgi1ikphkObIH0LrPnMTEAAEs6HPUvM7sw/dml61d95Og4SToK37ksj4skadDLSPjYE2MemA9nQ4qJjych5f7Y4MpE6Zhhgs5Uvy0s3L2nftxKy90HjJPDyhWUTIO/4+zXZ4Nw/wZBXYcm7MOP/wCcYOlwJRdmwexEcqb/3dzpkhNNKLSMiHq1BJyPt4sxBrBtTc+Cii+CXp2DXArPJ2dGgd13OBgVHYOn75niP1DUQ1QYG/hO8/WHNp7D6EygpPLb8znnH/vYLhUbtoHEy9BgNES3M8l53Q+sBEBIPvub5Q0kxrPgKXrj5zO1bHUozwvBTy4iIR2vQn8id4kOx2WBneh5pQd2J9guDwkzYvwoSulsdnsjJ7ZwPC16BnFQodULT880kImMrrP/ObLkoc3AdfHBF+fXjzoE2AyE4FlKWQH46dLkBOl4FDu/Kt9mobfnHXj7Qfkgd7tSZtdzVmhFqGRHxaA06GQkP9KFjfAi/78tm0Y5MrmrRFzZ8DzvmKBkRaxTnw5Lx5pw3zXpBQKTZDZJ7AFyl4PDB4R1Iy0Ml2BdthbnPgVF6bP3D28u/XnQHOH8sxJ8DKybD8ongHQhtL4NuI6B572PdN8mjztReepTNRjMNYBXxcA06GQG4oFUUv+/L5tdt6VzVop+ZjGyeBn0fsjo08UTHj70oLTG7OUoKIfcg5Bwwf1wl0PJiCGxktlwc3m7ecgDAO8DsJrHZIeU32P0r5B+B0iKzK6Qwy2zlAPj9q0pDsAOdAPYdLeg8zBzT4XKaY56y9kJkK2jSHVr1B/vRD9rLX4b+T5uT/Hn5np7jU0/5qptGxKM1/GSkZRTvzdvBr9vSMQZdjm3q/WY3TcZ2iGxpdXhyKkqKYe1nkH8YzhsD3n61f62dC+CHv5mDPmM6muMx0reUb5X4Iy+/8mMyTubQJvN3aFPofB2kLDaTmKY9IbI12B1QWkxpXgZpa2cT61uE7ZwboeedxxKkVpeeeBs+gdWP5yyilhERz9bgk5HuzSPwcdjZn1XIzoIAWrTsB9tmwbqv4KK/Wx2e1IarFNZ9CXOeg8zdZtnaz+Ga/0BsZ/NxcR4YrmPrHNllXlWSk2peWRXRArbPMQd+HtkF6744tnzKoorb9I8wx10Ex5pdLXuWmIlISGNI6AE+QWbC4Cwwf0qKILo9tLoEQhPMRCN9q5l8tBl0wsTJ5XSyNLczgwcPxtu7inEdUiNKRkQ8W4NPRvx9HHRrFsZvOw7z6/YMWnS+/mgy8qXZVfPHyyHFsxzZBSs/NLs3XE6z62Tf8mOtDIHRgAFpG+DdCyGxL5Q68UpZzECvYBylP8GBtXBoY/nXtXubr3e8c/8E3UfDoS3m1SaxncwxHQ4fM5k4Xm6a2XoS1ab676Hw5rU4AFIXdDWNiGdr8MkIwIWtovhtx2EWbj3ELcMuN5vXM7aaH1JxXa0OT8qUFJtdI2kbzDEaGdth9cdQWsn05H5hcOG90OPPZivItAfM6f6PXr5qA/xKsmHd5+bydi+z1SQg8uiMosUQ0gRaXmS2bjTpAa2PdoHEn3vyWIOizR/xeHYbeNn1pUPEk50dyUjrRrw0YwuLtmXg9ArEu81lsOE7WPofuPJtq8Nr+AoyzcQipoM5uLPgiDk3xp4lZsuH4TJbGg5trthaAWZrR8J55qWodoeZiHS6FvzDzOd9AmHYB3Bktzko1DsAZ8v+LPv5U85rVIgjpgO0u/zY8oVZ5vYiW6ll7Czg42XHpv+ziEc7K5KRLo1DiQz0ISOvmOW7jtDz/LFmMrLqY0i6DZokWx1i/VBSZLYq7FoA2almEtHhCrNVIXUNpG82r/Sw2SE4zkw09iyBtI2AYbZKtLzEvJqp7OqTP/INMQeQhiaAf7h5iWrLi6sXX3gz6H2/+bfTyaGQLrguGYzjj+Mu/ELNHzkr+Do0XkTE050VyYjdbqNvm0Z8s2ofczen0XPwedD1RnOWyqn3wx2zK44JONsYhtlF4h0AYQlmWXEuzdLn4PjoP+ZNBrNToaSg/HpVXJ5agU8w5GeYA0XBnLir5SXmIE+7l9lqUZaE6Fus1CENXhXxfGdFMgJwUbtovlm1jzmb03hkcHtzPoZNUyF1tTneYPBLDSMhSdsEWXvMpMJmM1szsveZXRjOfHOZ5hdCTCf4/WtzLoziXPNKj9wDgA3OuQm8/fFa8xnn/LEFIzjOnNEzooWZXKz53Fwvqq054DOsqdlikp1qjqlIOM/8CYiEjVPM7bXub16iqqRDzgBvJSMiHu+sSUb6tm6E3QZbDuay90g+TcKjYdCL8N1fzVkrcw7A9ZPrx2RRmSkw+5/mYM2uN0DHq825U9Z8XvllqX+0+K3Ky8vmzVj9MWAOAs31jcH/wrE4mp5nTvIV0eLYJFsAlzxpruMTcPLtdrrG/BE5g/y8lYyIeLqzJhkJDfAmqVk4y3YdYc7mQ9xyfjM450ZzQOU3fzbHMcx5Dvo/dfqCKMiE5RPMloOASOhwlTkuYuMUc3rwHndAYNSx5VPXmlf9FGSaYym8/WHjD+adWEuLzGUWvmr+lLF7QaP2x7pT7N7m3BjhzcEvBIpyYPPPZrdLkx5mchDYyGzFaNIDDq6HRW+A3YuSLjfxy4YcBp9/ecVxF+7t2auXiIhYxMerAbR4ijRwZ00yAtCvXTTLdh1h+u8HzGQEzBuG2b3g85vND+H2V0CTpLrZYGE29iXvE52VB64B8MWI8ndOnfmEOXZi71Lz8W/j4bw/m3NX/P41bPm56tdu3hu6DIPlk8xLYeO7mQM9z/0ThMSdOK7BL5s3WCu7uuR4TZJg2P8AMJxO2DitZvss4mE0gFXE851VycjlneN48efN/Lo9ndSsAuJC/c0n2g8x7/+x7gv4ZJjZUlCYabZIxHWBQf+q3twTx9s0FaY+gCNnPz0BY+IM866q3oHQ6WrYtwrS1puJiMPXbLlI3wzz/33sNWwOc7yFf7iZPOQfhqbnQdebzCuAbDbzZmjH30+lOuz2yhMRkQZIA1hFPN9ZlYw0iwykR2IES3ce5puV+7izX6tjTw76l9lqkXvQvM16mT1L4P2LzZaHoBjzFu5tB5lzZRzaZA4Yzd5nzoERHAtdhptTzf/6GgBGUAy23IPYDq4zX++qt80xHi4XrP8G9iyF8/5iJiNrvzDvKHxkF4Q1M2eIjWp98h3TQFCRKmkAq4jnO6uSEYDrkpqwdOdhvl65l7EXtTw2GVJABIyeZd6/xD/MnFjL4WOOx1j3hTkFOcDmqTDzH1VvYNGbx/7ueRclvf/O8q9e4/y8Gdi6DjcTETBbJzpfZ/6UOedG80dE6owGsIp4vrMuGRncOY4nvl/PjkN5rNqTSbem4ceeDGtq/hzv2veh9zjI2GZexbL5J/O28EGx0KitOU9GWFPz5m17lpgDYe1e5syuna8Dp5O00K6U3PiIbnomYgEfjRkR8XhnXTIS5OvFoE6xfLNqHx8s2lU+GalKdHvzB8zbubtc5S9vdbvLvAW94dJ9S0Q8hMaMiHi+s/IsHXVhIgBT1uxnW1pOzV+g0kTkqMAoJSIiHkTJiIjnOyvP0k6NQxnQIQaXAa//ss3qcETkNNIAVhHPd9aepfde2gaAH9fuZ/OBWrSOiEi94KtJz0Q83lmbjHSID2Fw51gMA178eZPV4YjIaeKnlhERj3dWn6X3D2iLw27jl01pLN6eYXU4InIa+CgZEfF4Z/VZ2rJREDf1MC/lfW7aRlwuw+KIRKSuBfmddRcNitQ7Z3UyAvC3S1sT5OvFun1ZfLxkt9XhiEgdu/qceKtDEJGTOOuTkaggX+4fYA5mfXbqRg1mFREROcPO+mQEYGSv5lzUthFFJS7u/nQl+cUlVockIiJy1lAyAthsNl66vitRQb5sOZjL3Z+soqTUZXVYIiIiZwUlI0dFBfnynxFJ+HrZ+WVTGo9+u04tJCIiImeAkpHjdGsazus3nIPNBl8s30ufF+fyzcq9VoclIiLSoCkZ+YPLOsXx3p+SaBoRQHpuEeO+WMM7czVlvIiIyOmiZKQSAzrGMmtcX/56UUsAXvx5M/+cugGnxpGIiIjUOSUjVfDxsvP3y9rx98vaAfD+gp1c9+5idmfkWRyZiIhIw6Jk5CT+elFL3rm5GyF+XqzZk8ng1xfw1Yq9GIZmaxUREakLSkaqYXDnOH6+tw89EiPIKy7lgS/XcNvkZWxL0wRpIiIip0rJSDXFh/nz6R3n88CANng7bMzdfIiBry3gie9/50hesdXhiYiI1FtKRmrAYbdx18WtmXFfX/p3iKHUZfC/xbvp++85vD5rK1kFTqtDFBERqXeUjNRCYlQg749I5pPR59EuNpjswhJenbWF85/7hT9/sJyf1qVqTImIiEg1KRk5Bb1aRTH1nt68eeO5tI0JpsBZyowNB/nrxysZNXkZKRn5VocoIiLi8bysDqC+c9htDO0az5Aucazfn82Pa1OZuHAnczYfYs6/5xAf6keCjx3fjWlc1D4WP2+H1SGLiIh4FCUjdcRms9GpcSidGodybbfGPP79epbszGB/ViH7sbPkk9X4ezvo0yaK65ISuLhdNA67zeqwRURELKdk5DRoHRPMp38+n7yiEpbtTGfSz8vYVhjAvsxCpq8/yPT1B0mI8OeW85txbbcm2G02/Lwd+Puo1URERM4+tRoz8s4775CYmIifnx9JSUksWLCgWuv9+uuveHl5cc4559Rms/VOoK8XF7SM5JpEF3PG9WbqPRfylz4tCAvwZs/hAp6btomkZ2dx7jMz6fr0DN6avVVTzkuDpXpDRKpS42Tk888/59577+Wxxx5j1apV9O7dm0GDBpGSknLC9bKyshgxYgSXXHJJrYOtz2w2Gx3jQ3lkcHsWP3wJL1zTmXaxwe7ni0tcvDRjC31enMNtk5byyswtbNifratypEFQvSEiJ1LjZOSVV17h9ttvZ/To0bRv357XXnuNhIQExo8ff8L1/vKXv3DTTTfRs2fPWgfbUPj7OLihR1N++ltv1j05gG3/HMSrw7sSHuBNalYhczYf4o1ftjL4jQVc9NJcnv9pI6v3ZCoxkXpL9YaInEiNxowUFxezYsUKHn744XLlAwYMYNGiRVWuN2nSJLZv385HH33Es88+e9LtFBUVUVRU5H6cnZ0NgNPpxOmsXxOLlcVbVdx+DjBcpQzpFEPfVpH8vj+LHen5/Lotg/lb09mdkc9783bw3rwdxIX6cX5iOJ0bh9Io2JfoYF+6NA7By3F6rtA+WeyeTLHXrVOJRfVGzXnie6C6FLs1PDX26sZTo2QkPT2d0tJSYmJiypXHxMRw4MCBStfZunUrDz/8MAsWLMDLq3qbe/7553nqqacqlM+ZM4eAgICahOwxZs6cWe1lw4EhYdC/G2zItLEmw8aGIzZSswr5dnUq365OdS8b7G1wTqRB6xCDxGCDEB9rY/c0ir1u5OfXfs4c1Ru150nvgZpS7NbwtNirW3fU6moam638JamGYVQoAygtLeWmm27iqaeeok2bNtV+/UceeYRx48a5H2dnZ5OQkEC/fv2IjIysTciWcTqdzJw5k/79++Pt7V3j9a8++rvIWcqSXUdYlZLJxgM5HMl3suNQHpkFThYcsLHgaJ3eNMKfrk1CaRcbzLkJYZybEFrrlpNTjd1Kir1ulbUynArVG9Xnie+B6lLs1vDU2Ktbd9QoGYmKisLhcFT4NpOWllbhWw9ATk4Oy5cvZ9WqVdx1110AuFwuDMPAy8uLGTNmcPHFF1dYz9fXF19f3wrl3t7eHnWQa+JUY/f29uaSDnFc0iHOXeYsdTF/yyHmbE5j+a4jbD6YQ8rhAlIOF/DDWvN/FOrvTXKzcDrGhxAf5k+IvzfZBU4KnaWc09Ts8jnZfCdn83G3kifFfipxqN6oPcVuDcVed6obS42SER8fH5KSkpg5cyZXX321u3zmzJlceeWVFZYPCQlh3bp15creeecdZs+ezVdffUViYmJNNi9/4O2wc0n7GC5pb1boWQVOVqUcYf3+bDbsz+bX7elk5jv5ZVMav2xKq/Q1gv28OL9FJMnNwmkeFUjr6CASowIr/cYqUhuqN0TkZGrcTTNu3DhuueUWkpOT6dmzJ//5z39ISUlhzJgxgNlUum/fPj744APsdjudOnUqt350dDR+fn4VyuXUhfp7c1HbaC5qGw1Aqctgzd5M1u3NYmNqNodyisgqcBLqb2aqS3cdJqewhJkbDjJzw0H364QHeHNu03C6Ng4h/ZANv82H6BAfRpNwf7YfymPTgWxiQvxoHhlIo+CK30RF/kj1hoicSI2TkeHDh5ORkcHTTz9NamoqnTp1Ytq0aTRr1gyA1NTUk84dIGeGw26jW9NwujUNr/T5UpfB7/uy+HV7Ouv3Z5OSkc/mg+Z4lNmb0pi9KQ1w8OG2VQAE+jjIKy4t9xpNwv1JbhZOUvMIkpuF0yYmWNPcSwWqN0TkRGo1gHXs2LGMHTu20ucmT558wnWffPJJnnzyydpsVuqYw26ja0IYXRPC3GXFJS7W789iZUomq3YfZkvKfhz+oWxNyyWvuBQfLzvt40I4nFfEviMF7D36893q/QAE+3rRPj6EJuH+ZOY72XM4n/NbRHLPJa0JD/Ams8BJmL/3abscWTyX6g0RqYruTSPl+HjZObdpOOc2Dcd5XhOmTdvL4ME9KTHs7EzPIzEq0H0PndyiElalHGH5riOs2H2EVSlHyCkqYenOwyzdeew1t6bl8vnyPRiGgbPUwGG3ERPsS3yYP80iAzm/RQTnJUbSJNwfu1pVRETOOkpGpFr8fRx0iA8pVxbk60Xv1o3o3boRACWlLjYdyGH7oVz2HikgxN+biAAf/jN/O2v2ZrnXK3UZ5t2MswpZvvsIX6/c6369UH9v8opL8PWyExHoezSBcdGnTSNGXZBIQoQ5X4RhGLgM1CUkItIAKBmROuPlsNOpcSidGoeWKx/UKZatabkE+XkRHezL4bxi9mcWsD+zkA2pWfy6LYP1+7PILSoht6jEvd7B7GOzaW4/lMekX3cRH+pHZJAvuzPyKHCW0iE+lJZRgQAE+DqIDfEjNtSfqEAvDhZAdoGTglwnmflOIgJ9aBTsi7e6iEREPIqSETnt7HYbbY+7KWBMiB8xIX6c2xQu7xLHgwPNOVN2pueRX1xKoI+DQqeLjLwivOx28opL+Oi33SzYmu5uUSmzZk8ma/ZkVrFlL55bPadcia+XnWuTmjD6wkRdwiwi4iGUjIhH8HbYaRMTXOXzAzvGciSvmB3peWTkFtE0MgA/Lwdr9mZyIKsQmw1yC0tIzSrkQHYhqZkF7DucS0GpDR+HndAAbzLziykqcfHJkhQ+WZKCn7edhPAAEiIC8HHYScspxMfLTpPwAIpKXKTnFNE0IoBzmoYR4ueNn7edxuH+RAf7kVdUgr+Pg6ggXdosInKqlIxIvREe6ENSYPmb7zQ/2kXzR06nk2nTpnFx/4EE+ftis9lwuQyW7TrMO3O3s2DrIQqdLram5bI1LfcPax92/7V4RwafL99T6TZsNujfPoZrk5qQEB6Aj5eN/OJSmkYEEBZwGm4SJCLSQCkZkQbNz9vh7oqx222c1yKS81pEUlziIjWrgJTD+aQczqfUZRAd7EuBs5R9Rwrw83YQEejDtrRc1u/PpsBZSl5RCXsO55NdWIKft51Cp4sZGw4y47gJ48AcVHteYgTNIgPwdtjxdtjx87bTPDKQ9nEhtI8L0cBbEZHjKBmRs5KPl51mkYE0i6y8ZeVESkpdeDnsbEvLYdKvu1i9x+wqKnEZ+HrZScspYtH2DBZtz6h0/bAAb9rFBpOZb95aOyEigGYRATSNDMBms3Ekt5B9B21E7jxM54QI94y5IiINlZIRkRoqm7CtVXQw/7y6c4Xnd2fkMW/LIbILnBSXmpcm5xQ62Z6Wx+/7ssjMd/LbjmNdQZsO5FSyFQef71gOmLPclroMDAN6JEZwYeso2sQE4+dtZ1d6Hn7eDnokRhDgY57O+cUl7M7IJyEigCBfL/ZlFrDzUB7JzcPx83bU/QERETlFSkZE6lizyEBG9Ky8xaWk1MXqPZnsPVJARKAPpYbBnsP5pGSY3UU2GwT5OtiwYy85tkD3DLdlpqzZz5Q1+yu8rrfDRqMgX1wGHMwpxDg6B0uTcH92Z+QD0CjYlz+d14wuTUJJjAqkSbi/ZsIVEY+gZETkDPJy2EluHkFy86qXMQffpjB4cG9yig22peXi520nv7iU+VsOsTLlCNsP5VHkLCUxKpD03GL2ZRaUu+Q52NeLnCKzhcRuM2+ieCiniFdnbTkWi91G08gAEiMD8XLYOJLvJDrYl06NQ/Gym4Nxfb3sBPg4oLigslBFROqEkhERDxYR6EOPxAj34/NbRFZYxjAM9h4p4HBeMQDxYf40CvZlX2YBWw7m0LlxKCF+3kxZs59fNh5kZ3oeO9PzKCpxseNQHjsO5ZV7vR/XplbYhqsov473TETkGCUjIvWczWYjISLAPVV+mcZh/jQO83c/vi6pCdclNQHA5TI4kF3IzvQ8dqTngWEQGuDDnsP5bEzNxmG3EeDjoKjERUFxKZlZWXx2RvdKRM4mSkZEzkJ2u434MH/iw/y5oFXUSZfPzs7ms7vOQGAiclbS6DURERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxVK2SkXfeeYfExET8/PxISkpiwYIFVS77zTff0L9/fxo1akRISAg9e/Zk+vTptQ5YROon1RsiUpUaJyOff/459957L4899hirVq2id+/eDBo0iJSUlEqXnz9/Pv3792fatGmsWLGCfv36MXToUFatWnXKwYtI/aB6Q0ROpMbJyCuvvMLtt9/O6NGjad++Pa+99hoJCQmMHz++0uVfe+01HnroIbp3707r1q157rnnaN26NT/88MMpBy8i9YPqDRE5Ea+aLFxcXMyKFSt4+OGHy5UPGDCARYsWVes1XC4XOTk5REREVLlMUVERRUVF7sfZ2dkAOJ1OnE5nTUK2XFm89S1uUOxW8cTYTyUW1Rs154nvgepS7Nbw1NirG0+NkpH09HRKS0uJiYkpVx4TE8OBAweq9Rovv/wyeXl5DBs2rMplnn/+eZ566qkK5XPmzCEgIKAmIXuMmTNnWh1CrSl2a3hS7Pn5+bVeV/VG7XnSe6CmFLs1PC326tYdNUpGythstnKPDcOoUFaZTz/9lCeffJLvv/+e6OjoKpd75JFHGDdunPtxdnY2CQkJ9OvXj8jIyNqEbBmn08nMmTPp378/3t7eVodTI4rdGp4Ye1krw6lQvVF9nvgeqC7Fbg1Pjb26dUeNkpGoqCgcDkeFbzNpaWkVvvX80eeff87tt9/Ol19+yaWXXnrCZX19ffH19a1Q7u3t7VEHuSYUuzUUe904lThUb9SeYreGYq871Y2lRgNYfXx8SEpKqtAMNHPmTHr16lXlep9++ikjR47kk08+4fLLL6/JJkWknlO9ISInU+NumnHjxnHLLbeQnJxMz549+c9//kNKSgpjxowBzKbSffv28cEHHwBmhTJixAhef/11zj//fPe3I39/f0JDQ+twV0TEU6neEJETqXEyMnz4cDIyMnj66adJTU2lU6dOTJs2jWbNmgGQmppabu6A9957j5KSEu68807uvPNOd/mtt97K5MmTT30PRMTjqd4QkROp1QDWsWPHMnbs2Eqf+2NFMXfu3NpsQkQaGNUbIlIV3ZtGRERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQspWRERERELKVkRERERCylZEREREQsVatk5J133iExMRE/Pz+SkpJYsGDBCZefN28eSUlJ+Pn50aJFC959991aBSsi9ZfqDRGpSo2Tkc8//5x7772Xxx57jFWrVtG7d28GDRpESkpKpcvv3LmTwYMH07t3b1atWsWjjz7KPffcw9dff33KwYtI/aB6Q0ROpMbJyCuvvMLtt9/O6NGjad++Pa+99hoJCQmMHz++0uXfffddmjZtymuvvUb79u0ZPXo0o0aN4qWXXjrl4EWkflC9ISIn4lWThYuLi1mxYgUPP/xwufIBAwawaNGiStdZvHgxAwYMKFc2cOBAJkyYgNPpxNvbu8I6RUVFFBUVuR9nZWUBcPjw4ZqE6xGcTif5+flkZGRUuq+eTLFbwxNjz8nJAcAwjBqvq3qj5jzxPVBdit0anhp7deuOGiUj6enplJaWEhMTU648JiaGAwcOVLrOgQMHKl2+pKSE9PR04uLiKqzz/PPP89RTT1Uob9OmTU3CFZE6lpOTQ2hoaI3WUb0hIierO2qUjJSx2WzlHhuGUaHsZMtXVl7mkUceYdy4ce7HmZmZNGvWjJSUlBpXhFbLzs4mISGBPXv2EBISYnU4NaLYreGJsRuGQU5ODvHx8bV+DdUb1eeJ74HqUuzW8NTYq1t31CgZiYqKwuFwVPg2k5aWVuFbTJnY2NhKl/fy8iIyMrLSdXx9ffH19a1QHhoa6lEHuSZCQkIUuwUUe92p7Qe66o3a87T3QE0odmt4YuzVqTtqNIDVx8eHpKQkZs6cWa585syZ9OrVq9J1evbsWWH5GTNmkJyc7FH9WiJyeqjeEJGTqfHVNOPGjeO///0vEydOZOPGjdx3332kpKQwZswYwGwqHTFihHv5MWPGsHv3bsaNG8fGjRuZOHEiEyZM4IEHHqi7vRARj6Z6Q0ROpMZjRoYPH05GRgZPP/00qampdOrUiWnTptGsWTMAUlNTy80dkJiYyLRp07jvvvt4++23iY+P54033uDaa6+t9jZ9fX154oknKm2C9XSK3RqK3bOo3qgZxW4NxW4dm1Gba/VERERE6ojuTSMiIiKWUjIiIiIillIyIiIiIpZSMiIiIiKW8vhkpKa3HbfC888/T/fu3QkODiY6OpqrrrqKzZs3l1tm5MiR2Gy2cj/nn3++RREf8+STT1aIKzY21v28YRg8+eSTxMfH4+/vz0UXXcT69estjPiY5s2bV4jdZrNx5513Ap51zOfPn8/QoUOJj4/HZrPx3XfflXu+Ose5qKiIu+++m6ioKAIDA7niiivYu3fvGdyL+sXT6476XG+A6o4z5WypOzw6GanpbcetMm/ePO68805+++03Zs6cSUlJCQMGDCAvL6/ccpdddhmpqanun2nTplkUcXkdO3YsF9e6devcz7344ou88sorvPXWWyxbtozY2Fj69+/vvvmRlZYtW1Yu7rJJsq6//nr3Mp5yzPPy8ujatStvvfVWpc9X5zjfe++9fPvtt3z22WcsXLiQ3NxchgwZQmlp6ZnajXqjPtQd9b3eANUdZ8JZU3cYHqxHjx7GmDFjypW1a9fOePjhhy2KqHrS0tIMwJg3b5677NZbbzWuvPJK64KqwhNPPGF07dq10udcLpcRGxtrvPDCC+6ywsJCIzQ01Hj33XfPUITV97e//c1o2bKl4XK5DMPw3GMOGN9++637cXWOc2ZmpuHt7W189tln7mX27dtn2O124+effz5jsdcX9bHuqE/1hmGo7rBCQ647PLZlpOy243+8jfiJbjvuKcpuXR4REVGufO7cuURHR9OmTRvuuOMO0tLSrAivgq1btxIfH09iYiI33HADO3bsAGDnzp0cOHCg3P/A19eXvn37etz/oLi4mI8++ohRo0aVu5Gapx7z41XnOK9YsQKn01lumfj4eDp16uRx/wur1de6o77VG6C6w2oNqe7w2GSkNrcd9wSGYTBu3DguvPBCOnXq5C4fNGgQH3/8MbNnz+bll19m2bJlXHzxxRQVFVkYLZx33nl88MEHTJ8+nffff58DBw7Qq1cvMjIy3Me5PvwPvvvuOzIzMxk5cqS7zFOP+R9V5zgfOHAAHx8fwsPDq1xGTPWx7qhv9Qao7vAEDanuqPF08GdaTW87brW77rqLtWvXsnDhwnLlw4cPd//dqVMnkpOTadasGVOnTuWaa64502G6DRo0yP13586d6dmzJy1btuR///ufe8BWffgfTJgwgUGDBpW7TbWnHvOq1OY4e+L/wlPUh/dtmfpWb4DqDk/SEOoOj20Zqc1tx6129913M2XKFObMmUOTJk1OuGxcXBzNmjVj69atZyi66gkMDKRz585s3brVPTLe0/8Hu3fvZtasWYwePfqEy3nqMa/OcY6NjaW4uJgjR45UuYyY6lvd0RDqDVDdYYWGVHd4bDJSm9uOW8UwDO666y6++eYbZs+eTWJi4knXycjIYM+ePcTFxZ2BCKuvqKiIjRs3EhcXR2JiIrGxseX+B8XFxcybN8+j/geTJk0iOjqayy+//ITLeeoxr85xTkpKwtvbu9wyqamp/P777x71v/AE9aXuaEj1BqjusEKDqjusGTdbPZ999pnh7e1tTJgwwdiwYYNx7733GoGBgcauXbusDq2cv/71r0ZoaKgxd+5cIzU11f2Tn59vGIZh5OTkGPfff7+xaNEiY+fOncacOXOMnj17Go0bNzays7Mtjf3+++835s6da+zYscP47bffjCFDhhjBwcHuY/zCCy8YoaGhxjfffGOsW7fOuPHGG424uDjL4y5TWlpqNG3a1Pj73/9ertzTjnlOTo6xatUqY9WqVQZgvPLKK8aqVauM3bt3G4ZRveM8ZswYo0mTJsasWbOMlStXGhdffLHRtWtXo6Sk5Izvj6erD3VHfa43DEN1x5lyttQdHp2MGIZhvP3220azZs0MHx8fo1u3buUue/MUQKU/kyZNMgzDMPLz840BAwYYjRo1Mry9vY2mTZsat956q5GSkmJt4IZhDB8+3IiLizO8vb2N+Ph445prrjHWr1/vft7lchlPPPGEERsba/j6+hp9+vQx1q1bZ2HE5U2fPt0AjM2bN5cr97RjPmfOnErfI7feeqthGNU7zgUFBcZdd91lREREGP7+/saQIUM84j3kqTy97qjP9YZhqO44U86WusNmGIZxplphRERERP7IY8eMiIiIyNlByYiIiIhYSsmIiIiIWErJiIiIiFhKyYiIiIhYSsmIiIiIWErJiIiIiFhKyYh4rLlz52Kz2cjMzLQ6FBGpR1R31D9KRkRERMRSSkZERETEUkpGpEqGYfDiiy/SokUL/P396dq1K1999RVwrBl06tSpdO3aFT8/P8477zzWrVtX7jW+/vprOnbsiK+vL82bN+fll18u93xRUREPPfQQCQkJ+Pr60rp1ayZMmFBumRUrVpCcnExAQAC9evVi8+bNp3fHReSUqO6QGrP21jjiyR599FGjXbt2xs8//2xs377dmDRpkuHr62vMnTvXffOm9u3bGzNmzDDWrl1rDBkyxGjevLlRXFxsGIZhLF++3LDb7cbTTz9tbN682Zg0aZLh7+/vvhGYYRjGsGHDjISEBOObb74xtm/fbsyaNcv47LPPDMM4doOo8847z5g7d66xfv16o3fv3kavXr2sOBwiUk2qO6SmlIxIpXJzcw0/Pz9j0aJF5cpvv/1248Ybb3Sf7GUnv2EYRkZGhuHv7298/vnnhmEYxk033WT079+/3PoPPvig0aFDB8MwDGPz5s0GYMycObPSGMq2MWvWLHfZ1KlTDcAoKCiok/0UkbqlukNqQ900UqkNGzZQWFhI//79CQoKcv988MEHbN++3b1cz5493X9HRETQtm1bNm7cCMDGjRu54IILyr3uBRdcwNatWyktLWX16tU4HA769u17wli6dOni/jsuLg6AtLS0U95HEal7qjukNrysDkA8k8vlAmDq1Kk0bty43HO+vr7lKpU/stlsgNlvXPZ3GcMw3H/7+/tXKxZvb+8Kr10Wn4h4FtUdUhtqGZFKdejQAV9fX1JSUmjVqlW5n4SEBPdyv/32m/vvI0eOsGXLFtq1a+d+jYULF5Z73UWLFtGmTRscDgedO3fG5XIxb968M7NTInLaqe6Q2lDLiFQqODiYBx54gPvuuw+Xy8WFF15IdnY2ixYtIigoiGbNmgHw9NNPExkZSUxMDI899hhRUVFcddVVANx///10796dZ555huHDh7N48WLeeust3nnnHQCaN2/OrbfeyqhRo3jjjTfo2rUru3fvJi0tjWHDhlm16yJyClR3SK1YO2RFPJnL5TJef/11o23btoa3t7fRqFEjY+DAgca8efPcA8R++OEHo2PHjoaPj4/RvXt3Y/Xq1eVe46uvvjI6dOhgeHt7G02bNjX+/e9/l3u+oKDAuO+++4y4uDjDx8fHaNWqlTFx4kTDMI4NQjty5Ih7+VWrVhmAsXPnztO9+yJSS6o7pKZshnFcR5xINc2dO5d+/fpx5MgRwsLCrA5HROoJ1R1SGY0ZEREREUspGRERERFLqZtGRERELKWWEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsZSSEREREbGUkhERERGxlJIRERERsdT/A59iKJqlmW8JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim([0,120])\n",
    "plt.ylim([0,1.0])\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim([0,120])\n",
    "plt.ylim([0,1.0])\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh2F_WVEOWyQ"
   },
   "source": [
    "You can see that both the training loss and validation loss decrease rapidly before 25 epochs. After that the gap between training loss and validation loss get larger, which means the model starts to overfit. In our later lectures, we will talk about what overfitting is, what causes overfitting and how to prevent overfitting when training deep learning models.\n",
    "\n",
    "In this particular case, the model looks like it performed better on the validation set than on the training set at the beginning of training. But that's not the case. Indeed, the validation loss is computed at the *end* of each epoch, while the training loss is computed *during* each epoch. So the training curve should be shifted by half an epoch to the left. If you do that, you will see the training and validation curves overlap almost perfectly at the beginning of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTEgV5SwOWyQ"
   },
   "source": [
    "## 5. Evaluate the model\n",
    "Once you are satisfied with your model's validation accuracy, you may evaluate the performance on the test set to estimate how the model generalize to new data. You can easily do this using the `evaluate()` method. The first output of `evaluate()` method is the loss of the model, and the second is the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1760357898637,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "0cfhzLQJOWyQ",
    "outputId": "6a2e2a5b-beb7-4fd9-99cf-1538a4464b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.6813 \n",
      "Test Accuracy: 74.03\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on both the test set\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ssC6CkoOWyQ"
   },
   "source": [
    "You could also use the `predict()` method to make predictions on new instances. The `predict()` outputs the likelihood of the diabetes. You need get the output class (0 or 1) by thresholding the probability with 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1760357898898,
     "user": {
      "displayName": "Vinay Namboodiri",
      "userId": "11142339437724471815"
     },
     "user_tz": -60
    },
    "id": "Zr_AIdjPOWyR",
    "outputId": "d27ab1ad-3691-4d84-9ac8-97425618d8c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "[0.6818561213767074, -0.7140203750690427, -0.6171265806311517, 0.8171097564727209, 0.9347490579239492, 0.2607356070976475, -0.11637246667483793, 0.8780908946942205] => 0 (expected 0)\n",
      "[-0.5263968613802863, -0.2766428261419786, 0.30191568625827075, 0.7522648048798231, -0.7012055319527017, 0.4805351763825151, -0.9542309996622792, -1.0359403793947792] => 0 (expected 0)\n",
      "[-0.5263968613802863, -0.40160784012113976, -0.2927587217290026, -1.3227736460929078, -0.7012055319527017, -0.1530047586150437, -0.9245197041662706, -1.0359403793947792] => 0 (expected 0)\n",
      "[1.2859826127552039, -0.43284909361593005, 0.572222235343395, -1.3227736460929078, -0.7012055319527017, -0.9546267171833829, 1.1493287214551267, 0.09507810074872061] => 0 (expected 0)\n",
      "[0.9839193670659557, 0.4731472577329885, 1.1128353335136434, -1.3227736460929078, -0.7012055319527017, -0.2693692364717384, -0.7700209675870263, 1.4871008455407204] => 0 (expected 0)\n",
      "[0.6818561213767074, -0.5578141075950912, 0.13973175680719618, 0.7522648048798231, 0.9347490579239492, 0.7391229049529471, -0.4313121989325286, 1.9221079532882204] => 0 (expected 0)\n",
      "[-0.8284601070695347, -1.5575342194283808, -1.1577396788014, -0.15556451742074667, -0.0468236960020413, -1.4976609471812905, -0.43428332848212947, -0.9489389578452793] => 0 (expected 0)\n",
      "[-1.130523352758783, -0.1204365586680271, -3.752682550018593, -1.3227736460929078, -0.7012055319527017, 0.2348768342406039, 1.3751345672247919, 0.9650923162437205] => 0 (expected 0)\n",
      "[0.07772962999821054, 1.0354898206392138, 0.13973175680719618, 0.5577299501011296, 0.3836906697549721, -0.08835782647243569, -0.3897163852381166, 0.3560823653972206] => 1 (expected 0)\n",
      "[0.37979287568745895, 0.8168010461756817, 0.46409961570934527, -1.3227736460929078, -0.7012055319527017, 0.22194744781208303, -0.7462519311902194, 2.7921221687832203] => 0 (expected 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marth\\AppData\\Local\\Temp\\ipykernel_33028\\390125595.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%s => %d (expected %d)' % ((X_test[i]).tolist(), y_predict[i], y_test[i]))\n"
     ]
    }
   ],
   "source": [
    "y_predict = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "for i in range(10):\n",
    "    print('%s => %d (expected %d)' % ((X_test[i]).tolist(), y_predict[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
